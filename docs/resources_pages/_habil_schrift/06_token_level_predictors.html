<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>7&nbsp; Token-level predictors – Modeling variationist corpus data: A mixed-effects framework</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./07_foregrounding_variation.html" rel="next">
<link href="./05_model_specification.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./06_token_level_predictors.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Token-level predictors</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Modeling variationist corpus data: A mixed-effects framework</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./01_research_objectives.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Research objectives</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_statistical_inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Statistical inferences</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_data_structure.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Data structure</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_statistical_models.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Statistical models: Integration of research objectives and data structure</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_model_specification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Model specification</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_token_level_predictors.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Token-level predictors</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_foregrounding_variation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Foregrounding variation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_modeling_tactics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Modeling tactics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./09_model_predictions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Model summary: Adjusted predictions and comparisons</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_case_study_I.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Case study I: The comparative alternation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_case_study_II.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Case study II: The genitive alternation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#context-and-composition" id="toc-context-and-composition" class="nav-link active" data-scroll-target="#context-and-composition"><span class="header-section-number">7.1</span> Context and composition</a></li>
  <li><a href="#differences-in-composition-risks-and-opportunities" id="toc-differences-in-composition-risks-and-opportunities" class="nav-link" data-scroll-target="#differences-in-composition-risks-and-opportunities"><span class="header-section-number">7.2</span> Differences in composition: Risks and opportunities</a></li>
  <li><a href="#within--and-between-comparisons-illustration-using-synthetic-data" id="toc-within--and-between-comparisons-illustration-using-synthetic-data" class="nav-link" data-scroll-target="#within--and-between-comparisons-illustration-using-synthetic-data"><span class="header-section-number">7.3</span> Within- and between-comparisons: Illustration using synthetic data</a>
  <ul class="collapse">
  <li><a href="#composition-of-clusters" id="toc-composition-of-clusters" class="nav-link" data-scroll-target="#composition-of-clusters"><span class="header-section-number">7.3.1</span> Composition of clusters</a></li>
  <li><a href="#within-cluster-differences" id="toc-within-cluster-differences" class="nav-link" data-scroll-target="#within-cluster-differences"><span class="header-section-number">7.3.2</span> Within-cluster differences</a></li>
  <li><a href="#between-cluster-differences" id="toc-between-cluster-differences" class="nav-link" data-scroll-target="#between-cluster-differences"><span class="header-section-number">7.3.3</span> Between-cluster differences</a></li>
  <li><a href="#comparison-of-between-cluster-and-within-cluster-differences" id="toc-comparison-of-between-cluster-and-within-cluster-differences" class="nav-link" data-scroll-target="#comparison-of-between-cluster-and-within-cluster-differences"><span class="header-section-number">7.3.4</span> Comparison of between-cluster and within-cluster differences</a></li>
  </ul></li>
  <li><a href="#within--and-between-comparisons-illustration-using-the-ing-data" id="toc-within--and-between-comparisons-illustration-using-the-ing-data" class="nav-link" data-scroll-target="#within--and-between-comparisons-illustration-using-the-ing-data"><span class="header-section-number">7.4</span> Within- and between-comparisons: Illustration using the ING data</a>
  <ul class="collapse">
  <li><a href="#composition-of-clusters-1" id="toc-composition-of-clusters-1" class="nav-link" data-scroll-target="#composition-of-clusters-1"><span class="header-section-number">7.4.1</span> Composition of clusters</a></li>
  <li><a href="#within-cluster-differences-1" id="toc-within-cluster-differences-1" class="nav-link" data-scroll-target="#within-cluster-differences-1"><span class="header-section-number">7.4.2</span> Within-cluster differences</a></li>
  <li><a href="#between-cluster-differences-1" id="toc-between-cluster-differences-1" class="nav-link" data-scroll-target="#between-cluster-differences-1"><span class="header-section-number">7.4.3</span> Between-cluster differences</a></li>
  </ul></li>
  <li><a href="#interpretation-of-between-and-within-comparisons" id="toc-interpretation-of-between-and-within-comparisons" class="nav-link" data-scroll-target="#interpretation-of-between-and-within-comparisons"><span class="header-section-number">7.5</span> Interpretation of between and within comparisons</a></li>
  <li><a href="#model-specification-for-between-and-within-comparisons" id="toc-model-specification-for-between-and-within-comparisons" class="nav-link" data-scroll-target="#model-specification-for-between-and-within-comparisons"><span class="header-section-number">7.6</span> Model specification for between and within comparisons</a>
  <ul class="collapse">
  <li><a href="#model-specification-two-options" id="toc-model-specification-two-options" class="nav-link" data-scroll-target="#model-specification-two-options"><span class="header-section-number">7.6.1</span> Model specification: Two options</a></li>
  <li><a href="#choosing-between-the-two-specifications" id="toc-choosing-between-the-two-specifications" class="nav-link" data-scroll-target="#choosing-between-the-two-specifications"><span class="header-section-number">7.6.2</span> Choosing between the two specifications</a></li>
  <li><a href="#failure-to-partition-between--and-within-differences" id="toc-failure-to-partition-between--and-within-differences" class="nav-link" data-scroll-target="#failure-to-partition-between--and-within-differences"><span class="header-section-number">7.6.3</span> Failure to partition between- and within-differences</a></li>
  <li><a href="#example-following-context" id="toc-example-following-context" class="nav-link" data-scroll-target="#example-following-context"><span class="header-section-number">7.6.4</span> Example: Following context</a></li>
  <li><a href="#simulation" id="toc-simulation" class="nav-link" data-scroll-target="#simulation"><span class="header-section-number">7.6.5</span> Simulation</a></li>
  </ul></li>
  <li><a href="#causal-assumptions-for-the-identification-of-contextual-effects" id="toc-causal-assumptions-for-the-identification-of-contextual-effects" class="nav-link" data-scroll-target="#causal-assumptions-for-the-identification-of-contextual-effects"><span class="header-section-number">7.7</span> Causal assumptions for the identification of contextual effects</a>
  <ul class="collapse">
  <li><a href="#token-level-confounding" id="toc-token-level-confounding" class="nav-link" data-scroll-target="#token-level-confounding"><span class="header-section-number">7.7.1</span> Token-level confounding</a></li>
  <li><a href="#cluster-level-confounding" id="toc-cluster-level-confounding" class="nav-link" data-scroll-target="#cluster-level-confounding"><span class="header-section-number">7.7.2</span> Cluster-level confounding</a></li>
  <li><a href="#understanding-bias" id="toc-understanding-bias" class="nav-link" data-scroll-target="#understanding-bias"><span class="header-section-number">7.7.3</span> Understanding bias</a></li>
  <li><a href="#simulation-1" id="toc-simulation-1" class="nav-link" data-scroll-target="#simulation-1"><span class="header-section-number">7.7.4</span> Simulation</a></li>
  <li><a href="#bias-decreases-with-increasing-cluster-size" id="toc-bias-decreases-with-increasing-cluster-size" class="nav-link" data-scroll-target="#bias-decreases-with-increasing-cluster-size"><span class="header-section-number">7.7.5</span> Bias decreases with increasing cluster size</a></li>
  <li><a href="#tools-for-consistent-estimation" id="toc-tools-for-consistent-estimation" class="nav-link" data-scroll-target="#tools-for-consistent-estimation"><span class="header-section-number">7.7.6</span> Tools for consistent estimation</a></li>
  </ul></li>
  <li><a href="#additional-complexities" id="toc-additional-complexities" class="nav-link" data-scroll-target="#additional-complexities"><span class="header-section-number">7.8</span> Additional complexities</a>
  <ul class="collapse">
  <li><a href="#correct-specification-of-the-between-pattern" id="toc-correct-specification-of-the-between-pattern" class="nav-link" data-scroll-target="#correct-specification-of-the-between-pattern"><span class="header-section-number">7.8.1</span> Correct specification of the between-pattern</a></li>
  <li><a href="#population-averaged-vs.-cluster-specific-estimates" id="toc-population-averaged-vs.-cluster-specific-estimates" class="nav-link" data-scroll-target="#population-averaged-vs.-cluster-specific-estimates"><span class="header-section-number">7.8.2</span> Population-averaged vs.&nbsp;cluster-specific estimates</a></li>
  <li><a href="#crossed-clustering-structures" id="toc-crossed-clustering-structures" class="nav-link" data-scroll-target="#crossed-clustering-structures"><span class="header-section-number">7.8.3</span> Crossed clustering structures</a></li>
  <li><a href="#random-slopes" id="toc-random-slopes" class="nav-link" data-scroll-target="#random-slopes"><span class="header-section-number">7.8.4</span> Random slopes</a></li>
  <li><a href="#contextual-effects-for-categorical-predictors" id="toc-contextual-effects-for-categorical-predictors" class="nav-link" data-scroll-target="#contextual-effects-for-categorical-predictors"><span class="header-section-number">7.8.5</span> Contextual effects for categorical predictors</a></li>
  </ul></li>
  <li><a href="#within--and-between-effects-and-fallacies" id="toc-within--and-between-effects-and-fallacies" class="nav-link" data-scroll-target="#within--and-between-effects-and-fallacies"><span class="header-section-number">7.9</span> Within- and between-effects and fallacies</a></li>
  <li><a href="#tools" id="toc-tools" class="nav-link" data-scroll-target="#tools"><span class="header-section-number">7.10</span> Tools</a>
  <ul class="collapse">
  <li><a href="#plotting-the-composition-of-clusters-using-a-dot-diagram" id="toc-plotting-the-composition-of-clusters-using-a-dot-diagram" class="nav-link" data-scroll-target="#plotting-the-composition-of-clusters-using-a-dot-diagram"><span class="header-section-number">7.10.1</span> Plotting the composition of clusters using a dot diagram</a></li>
  <li><a href="#exploring-between-cluster-trends-using-a-bubble-chart" id="toc-exploring-between-cluster-trends-using-a-bubble-chart" class="nav-link" data-scroll-target="#exploring-between-cluster-trends-using-a-bubble-chart"><span class="header-section-number">7.10.2</span> Exploring between-cluster trends using a bubble chart</a></li>
  <li><a href="#recoding-token-level-predictors-in-r" id="toc-recoding-token-level-predictors-in-r" class="nav-link" data-scroll-target="#recoding-token-level-predictors-in-r"><span class="header-section-number">7.10.3</span> Recoding token-level predictors in R</a></li>
  <li><a href="#model-syntax" id="toc-model-syntax" class="nav-link" data-scroll-target="#model-syntax"><span class="header-section-number">7.10.4</span> Model syntax</a></li>
  </ul></li>
  <li><a href="#literature-on-between--and-within-comparisons" id="toc-literature-on-between--and-within-comparisons" class="nav-link" data-scroll-target="#literature-on-between--and-within-comparisons"><span class="header-section-number">7.11</span> Literature on between- and within comparisons</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-token-level-predictors" class="quarto-section-identifier"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Token-level predictors</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="context-and-composition" class="level2 page-columns page-full" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="context-and-composition"><span class="header-section-number">7.1</span> Context and composition</h2>
<p>Recall that token-level variables are attributes of the specific context of the corpus hit. To measure them, we need to inspect the environment of a particular instance. In natural (observational) data settings, the token-level variables are free to vary over clusters. This is true for both clustering variables, Item and Speaker. For instance, words may differ in the types of contexts in which they occur - they may partake in different syntactic constructions, they may differ in collocational preferences, etc. It seems that in many cases we would in fact expect words to differ, perhaps systematically, in their co-textual surroundings, or milieu. This possibility, which often turns out to be a reality, forms the backbone of the present chapter.</p>
<p>Let us start by introducing terminology. We will use the term <em>context</em> to refer to the immediate environment of a corpus hit, i.e.&nbsp;what we see when inspecting a concordance. Token-level variables are among the features that characterize the context. We now need a term for describing context-related differences between cluster, i.e.&nbsp;for describing the way in which, say, words vary in their surroundings. When describing such differences, we will talk about the <em>composition</em> of – or, equivalently, the makeup of the tokens belonging to – a particular word. We can therefore describe the composition of clusters with regard to different token-level variables.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> The composition of a word then reflects the within-word distribution of a given token-level predictor. In linguistic terms, it describes the co-textual milieu that is typical for this word in the corpus at hand. Put differently, the composition of a word for a specific token-level variable describes one particular aspect of the contexts to which this word is typically drawn. Of course, we may be interested in the composition of words along different lines, i.e.&nbsp;looking at different token-level variables.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;Even though this term does not fit language data structures that weel, we nevertheless adopt it from the literature <span class="citation" data-cites="Diez-Roux2002">(cf. <a href="references.html#ref-Diez-Roux2002" role="doc-biblioref">Diez Roux 2002</a>)</span>. As a label, it is more transparent when considering human beings as tokens and higher-level units such as classrooms or school as clusters. Thus, it makes more sense to talk about the composition of class, or school, e.g.&nbsp;in terms of socio-economic characteristics of its students.</p></div></div><p>If clusters differ in composition, level-1 variables will vary both within and between clusters. In natural language data, it is often the case that the distribution of token-level predictor values varies from cluster to cluster. Statistically, differences in composition can be described as an <em>association</em> between token-level variable and clustering variable. The strength of this association reflects the degree of heterogeneity among clusters, i.e.&nbsp;to which extent they differ in the kinds of contexts in which they surface.</p>
<p>For language-internal clustering factors such as Item, variation in co-textual surroundings is to some extent systematic. This means, based on our knowledge about language (use), we can anticipate certain compositional differences among words, or, once they have been observed, they usually make sense. It is also of substantive interest, since the typical environment in which a word appears may have an influence on the behavior of this particular word. For instance, if a word such as <em>trying</em> tends to occur almost exclusively in contexts that are, for coarticulatory reasons, adverse to <em>ing</em>, this may, over generations of speakers, lead to a diachronic trend towards <em>in</em>.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> In contrast to Item, differences in composition among speakers will typically be haphazard, and of little substantive interest. Thus, we may observe that the tokens produced by a particular speaker differ from other speakers in our sample. It would usually seem, however, that this is reflects random, rather than systematic, variation.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;See agent-based model.</p></div></div><ul>
<li>micro-scale vs.&nbsp;macro-scale</li>
<li>studies discussing the possibility of contextual effects: Bybee 2002, Torres Cacoullos 199; cited in Barth &amp; Kapatsinski 2014: 212-213</li>
</ul>
</section>
<section id="differences-in-composition-risks-and-opportunities" class="level2 page-columns page-full" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="differences-in-composition-risks-and-opportunities"><span class="header-section-number">7.2</span> Differences in composition: Risks and opportunities</h2>
<p>As we will discuss in the present chapter, situations where clusters differ in composition bear both risks and opportunities. On the one hand, we need to be cautious because a multilevel model may yield misleading patterns for a token-level predictor. As will be seen throughout the following sections, an uncarefully specified multilevel model will return an estimate for the token-level predictor that blends two types of comparison. Only if these two patterns are sufficiently similar is there no cause to worry. We therefore need to check whether the data suggest sufficient similarity, and whether we would expect different patterns on substantive grounds. We will see that, in cases where the patterns diverge, the course of action will depend on the underlying causal structure.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;Are experimental data really free from this bias threat?</p></div></div><p>On the other hand, the two types of comparisons, or patterns, that we have loosely referred to so far, open up new and linguistically meaningful dimensions of variation for theoretical description and empirical analysis. To this end, multilevel models are a critical tool, since it is difficult (if not impossible) to separate these two types of pattern using other data-analytic techniques. Again, however, the linguistic interpretation we may attach to these comparisons depends on the underlying causal structure.</p>
<p>We begin by illustrating the difference between these two types of patterns, first using synthetic data and then turning to the ING data.</p>
</section>
<section id="within--and-between-comparisons-illustration-using-synthetic-data" class="level2 page-columns page-full" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="within--and-between-comparisons-illustration-using-synthetic-data"><span class="header-section-number">7.3</span> Within- and between-comparisons: Illustration using synthetic data</h2>
<p>Consider, as an example, a hypothetical data set of 20 words. There is a binary token-level predictor, with one category favorable to ing and the other category unfavorable to ing.</p>
<section id="composition-of-clusters" class="level3 page-columns page-full" data-number="7.3.1">
<h3 data-number="7.3.1" class="anchored" data-anchor-id="composition-of-clusters"><span class="header-section-number">7.3.1</span> Composition of clusters</h3>
<p>The composition of clusters - i.e.&nbsp;words - with respect to this binary predictor varies: The proportion of favorable contexts ranges from .08 to .94. The differences in composition are shown graphically in <a href="#fig-illustration-composition" class="quarto-xref">Figure&nbsp;<span>7.1</span></a>. Panel (a) shows the composition of the 20 verbs using a bar chart. Words are ordered by the proportion of favorable contexts, which are shown with gray fill color. Most words are attracted to favorable contexts. Panel (b) shows a more compact display of this distribution: Each word is represented by a filled circle, which indicates its composition, i.e.&nbsp;its share of favorable contexts. Note that the y-axis label has changed accordingly. In what follows, we will usually prefer compact displays of this kind. Panel (b) also introduces two useful terms: The word-specific average for the token predictor will be referred to as the <em>cluster mean</em>. The average over all tokens in the data set, ignoring cluster membership, is called the <em>overall mean</em>. Here, the overall mean is identical to the <em>grand mean</em>, which is the average of the cluster means, disregarding the number of tokens per cluster.<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;The distinction between the <em>overall</em> and the <em>grand</em> mean is not usually made in the literature, but it is a useful distinction in observational, unbalanced data settings, since the two measures may differ.</p></div></div><div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-illustration-composition" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" width="422.4">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-illustration-composition-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06_token_level_predictors_files/figure-html/fig-illustration-composition-1.png" id="fig-illustration-composition" class="img-fluid figure-img" width="422">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig quarto-uncaptioned margin-caption" id="fig-illustration-composition-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.1
</figcaption>
</figure>
</div>
</div>
</div>
<p>Whenever clusters differ in composition, a token-level predictor varies at two levels. First, it varies within clusters: For a specific cluster, some tokens appear in favorable contexts, others in unfavorable contexts. Further, it varies between clusters: Favorable contexts may be overrepresented in some clusters relative to others. In other words, with regard to our token-level predictor, clusters differ in composition. Let us extend our terminology: When clusters differ in composition, as in <a href="#fig-illustration-composition" class="quarto-xref">Figure&nbsp;<span>7.1</span></a>, the variation of the token-level predictor can be <em>partitioned</em>, or <em>decomposed</em> into two components, a <em>within-cluster component</em> and a <em>between-cluster component</em> <span class="citation" data-cites="Neuhaus_Kalbfleisch1998">(cf. <a href="references.html#ref-Neuhaus_Kalbfleisch1998" role="doc-biblioref">Neuhaus and Kalbfleisch 1998</a>)</span>.</p>
<p>It is informative to summarize and compare the two components. One way to go about this is to fit a variance components model (i.e.&nbsp;a multilevel model) to the token-level variable, with a variance component (i.e.&nbsp;random intercept) for Item (see Section data-structure-systematic-component). This gives us the following measures of variation, expressed on the proportion scale:<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;As a further measure of variation, the intraclass correlation is 0.18.</p></div></div><ul>
<li>Overall SD: 0.49</li>
<li>Within SD: 0.28</li>
<li>Between SD: 0.18</li>
</ul>
<p>This allows us to compare the two components. A between SD close to zero would indicate that differences in composition may be negligible - which is not the case in our illustrative example. In data settings where we are dealing with two clustering factors, a further informative comparison is that of the two between SDs, one for each clustering variable. Far language data settings, we would expect the between SD for Item to be larger than that for Speaker.</p>
<p>Token-level variables that vary both within and between clusters can be studied at these two levels. First, we can take a purely <em>within-cluster perspective</em> and look at the pattern the token-level predictor forms in a specific cluster (i.e.&nbsp;Speaker or Item). We can also take a <em>between-cluster perspective</em> and study a token-level predictor at level 2. We would then be interested in whether the observed differences between clusters in terms of the outcome proportion are in line with the observed within-cluster patterns. Put differently, we may examine whether within-cluster patterns extend in a direct manner to the higher level. In the illustrative example at hand, we would expect the raw outcome proportions for the individual words in our example to reflect differences in composition, with words that tend to occur in favorable contexts showing a higher proportion of ing, on average.</p>
</section>
<section id="within-cluster-differences" class="level3 page-columns page-full" data-number="7.3.2">
<h3 data-number="7.3.2" class="anchored" data-anchor-id="within-cluster-differences"><span class="header-section-number">7.3.2</span> Within-cluster differences</h3>
<p>Let us first consider the within-cluster perspective. To this end, we can compare, separately for each word, the share of ing in favorable vs.&nbsp;unfavorable contexts. In panel (a) in <a href="#fig-illustration-within" class="quarto-xref">Figure&nbsp;<span>7.2</span></a>, each word is represented by a line that connects the observed proportion of ing in these two contexts. Such a plot is sometimes referred to as a <em>spaghetti plot</em>. All lines, except for one, slope upwards, indicating a higher share of ing in favorable contexts - as expected. Panel (b) directly shows the word-specific differences between these two contexts; words do not appear in a specific order. We can see that (again with the exception of one word) all differences are positive, indicating a consistent pattern across words: Tokens in favorable contexts show higher shares of ing. The observed differences average at about .40. At the right margin of panel (b), the distribution of differences is summarized with a <em>dot diagram</em>. This diagram brings into view the variation among clusters in the within-differences.</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-illustration-within" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" width="422.4">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-illustration-within-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06_token_level_predictors_files/figure-html/fig-illustration-within-1.png" id="fig-illustration-within" class="img-fluid figure-img" width="422">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig quarto-uncaptioned margin-caption" id="fig-illustration-within-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.2
</figcaption>
</figure>
</div>
</div>
</div>
<p>For the estimation of within-cluster differences using regression modeling, we have various options. Further below, we will see how to isolate within-cluster comparisons using multilevel modeling. Here, we note that there are alternative strategies. Thus, within-differences can be estimated with a fixed-effects regression model, where either (i) the clustering variable (i.e.&nbsp;Item) is added as a fixed predictor or, alternatively, (ii) all level-1 variables and the outcome are de-meaned, i.e.&nbsp;the regression is run on mean-centered deviation scores for these variables.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a>. These approaches implicitly control for level-2 predictors, both observed and unobserved, because characteristics of clusters are held constant in the comparison via (i) the fixed effects, or (ii) by subtracting cluster means prior to modeling. In a way, each cluster serves as their own control.</p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;On these approaches, see <span class="citation" data-cites="Rabe-Hesketh_Skrondal2022">Rabe-Hesketh and Skrondal (<a href="references.html#ref-Rabe-Hesketh_Skrondal2022" role="doc-biblioref">2021</a>)</span>, p.&nbsp;162. This strategy is popular in disciplines where research interest is exclusively in within-cluster patterns. Examples are econometrics, applied research in public policy, and longitudinal and panel data modeling more generally <span class="citation" data-cites="Schnuck_Perales2017">(cf. <a href="references.html#ref-Schnuck_Perales2017" role="doc-biblioref">Schnuck and Perales 2017, 95</a>)</span>.</p></div></div></section>
<section id="between-cluster-differences" class="level3 page-columns page-full" data-number="7.3.3">
<h3 data-number="7.3.3" class="anchored" data-anchor-id="between-cluster-differences"><span class="header-section-number">7.3.3</span> Between-cluster differences</h3>
<p>Next, we consider the <em>between-cluster perspective</em>. Panel (a) in <a href="#fig-illustration-compositional" class="quarto-xref">Figure&nbsp;<span>7.3</span></a> shows the 20 verbs in our data set. The y-axis represents the share of ing and the x-axis shows the composition of the word, i.e.&nbsp;the proportion of tokens that occur in favorable contexts. This is the same distribution that appeared in <a href="#fig-illustration-composition" class="quarto-xref">Figure&nbsp;<span>7.1</span></a>. Thus, if the points were to be dropped onto the horizontal axis, they would form the dot diagram that we saw at the right margin in <a href="#fig-illustration-within" class="quarto-xref">Figure&nbsp;<span>7.2</span></a>. The trend line gives a summary of the pattern in the plot, i.e.&nbsp;it shows how the average share of ing varies across different compositions: Verbs that predominantly feature in favorable contexts tend to show a higher share of -ing. Given the within-cluster patterns that we just saw in <a href="#fig-illustration-within" class="quarto-xref">Figure&nbsp;<span>7.2</span></a>, this makes sense. Looked at from a different perspective, the token-level predictor accounts for some of the variability that we observe among the words in terms of the share of ing.<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a> It helps us understand the observed variation among words in terms of the outcome proportion a little better.<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn7"><p><sup>7</sup>&nbsp;We can compare the variability among words before and after adjusting for the token-level predictor. This tells us how much of the raw variation may be attributed to differences in composition. To this end, we compute a ratio of two random-intercept variances: the one from a model including the token-level predictor divided by that not including the token-level predictor <span class="citation" data-cites="Bingenheimer_Raudenbush2004">(see <a href="references.html#ref-Bingenheimer_Raudenbush2004" role="doc-biblioref">Bingenheimer and Raudenbush 2004, 61</a>)</span>. Here, this ratio is 0.86, which means that 0.14 of the variation among words is accounted for by differences in composition.</p></div><div id="fn8"><p><sup>8</sup>&nbsp;The distributional properties of a word can be considered part of its inherent characteristics.</p></div></div><p>It is often informative to ask about the amount of variation among verbs that remains after we adjust for differences in composition, i.e.&nbsp;the observed imbalance in token-level predictors. This adjusted estimate is a better representation of what is idiosyncratic about a word, or, at a different level of description, the the amount of unexplained variability among words that is not accounted for by the predictors in our model. We can use the model to compute <em>adjusted cluster means</em>, which reflect, for each specific word, the expected share of ing if the proportion of favorable contexts were equal across all words. To arrive at this adjusted estimate, we need to take into account the within-cluster difference between favorable and unfavorable contexts.</p>
<p>Panel (b) in <a href="#fig-illustration-compositional" class="quarto-xref">Figure&nbsp;<span>7.3</span></a> illustrates the adjustment we are making. The filled circles are the same ones as in panel (a). They represent the observed share of ing plotted against the composition of the cluster. For our adjustment, we first overlay, for each word, a model-based regression line that covers its location in the scatter plot. On the model scale (here: logits), all regression lines have the same slope, which represents the observed within-cluster difference. On the data scale (here: proportions), we end up with a set of curves. Now, each word is sitting on a grey curve. This curve traces, for this specific word, the expected overall share of ing for the range of possible compositions. Thus, shifting a given point along its line, we can determine its model-implied share of ing for different proportions of favorable and unfavorable contexts.</p>
<p>We can set cluster composition to a fixed value across all clusters and thereby remove from the raw proportion of ing for each word the variation that may be linked to the within-cluster differences. We are adjusting for the observed imbalance. In order to do so, we need to pick a reference composition. There are different options. Here, we take the value representing a balanced distribution of favorable and unfavorable contexts (both 50%).<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a> The blue curve in the center represents the within-cluster difference of the token-level predictor. It connects values of about .25 (left-hand side) and .70 (right-hand side), producing an absolute difference corresponding to the one we saw in <a href="#fig-illustration-within" class="quarto-xref">Figure&nbsp;<span>7.2</span></a>. This line represents a regression slope and was determined with a logistic regression model. Note that this slope expresses differences on the logit scale, but we have instead plotted on the probability scale. As a result, curves closer to 0 or 1 become flatter.</p>
<div class="no-row-height column-margin column-container"><div id="fn9"><p><sup>9</sup>&nbsp;For this comparison, it would also make sense to use the grand mean.</p></div></div><div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-illustration-compositional" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" width="422.4">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-illustration-compositional-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06_token_level_predictors_files/figure-html/fig-illustration-compositional-1.png" id="fig-illustration-compositional" class="img-fluid figure-img" width="422">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig quarto-uncaptioned margin-caption" id="fig-illustration-compositional-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.3
</figcaption>
</figure>
</div>
</div>
</div>
<p>This leaves us with a set of adjusted cluster estimates. Panel (c) takes these adjusted estimates and plots them (again) against the composition of the cluster. After adjusting for the within-cluster differences, there is little systematic variation left – the slope of the regression line is close to zero. This indicates that the pattern in panel (a) reflects within-cluster differences only. Once these are subtracted out, the clusters no longer vary systematically across different compositions. The pattern in panel (a) is then referred to as reflecting a <em>compositional effect</em>.<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> Compositional effects are those differences among clusters that are due to differences among clusters in the distribution of level-1 variables.</p>
<div class="no-row-height column-margin column-container"><div id="fn10"><p><sup>10</sup>&nbsp;This use of the term <em>compositional effect</em> follows <span class="citation" data-cites="Duncan_etal1998 Diez-Roux2002">Rabe-Hesketh and Skrondal (<a href="references.html#ref-Rabe-Hesketh_Skrondal2022" role="doc-biblioref">2021</a>)</span>.</p></div><div id="fn11"><p><sup>11</sup>&nbsp;The term <em>contextual effect</em> is used differently in the literature <span class="citation" data-cites="Diez-Roux2002">(see <a href="references.html#ref-Diez-Roux2002" role="doc-biblioref">Diez Roux 2002</a>)</span>. We follow <span class="citation" data-cites="Castellano_etal2014">Castellano, Rabe-Hesketh, and Skrondal (<a href="references.html#ref-Castellano_etal2014" role="doc-biblioref">2014</a>)</span> and <span class="citation" data-cites="Rabe-Hesketh_Skrondal2022">Rabe-Hesketh and Skrondal (<a href="references.html#ref-Rabe-Hesketh_Skrondal2022" role="doc-biblioref">2021</a>)</span>, p.&nbsp;167 and make a distinction between a <em>contextual effect</em> and a <em>compositional effect</em>. Note that some authors use these terms interchangeably <span class="citation" data-cites="Raudenbush_Bryk2002">(e.g. <a href="references.html#ref-Raudenbush_Bryk2002" role="doc-biblioref">Raudenbush and Bryk 2002, 140</a>)</span>.</p></div></div><p>It could also be the case, however, that after adjusting for the within-cluster difference, the residual variation among words still shows systematic patterns when drawn against cluster composition. This would indicate that the token-level predictor produces different patterns at these levels, since the within-cluster pattern would differ from the between-cluster pattern. The discrepancy between the two is often referred to as a <em>contextual effect</em>.<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a></p>
</section>
<section id="comparison-of-between-cluster-and-within-cluster-differences" class="level3 page-columns page-full" data-number="7.3.4">
<h3 data-number="7.3.4" class="anchored" data-anchor-id="comparison-of-between-cluster-and-within-cluster-differences"><span class="header-section-number">7.3.4</span> Comparison of between-cluster and within-cluster differences</h3>
<p>We can inspect the agreement between the within-cluster pattern and the between-cluster pattern by plotting them into the same display. That is, we directly compare the dashed curve from <a href="#fig-illustration-compositional" class="quarto-xref">Figure&nbsp;<span>7.3</span></a> a to the blue curve in <a href="#fig-illustration-compositional" class="quarto-xref">Figure&nbsp;<span>7.3</span></a> b. This comparison appears in <a href="#fig-illustration-comparison-between-within" class="quarto-xref">Figure&nbsp;<span>7.4</span></a>, where the between-pattern is shown as a dashed line and the within-pattern as a solid line. Note that the line for the between-pattern only covers the range of compositions supported by the data.</p>
<div class="cell page-columns page-full">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-illustration-comparison-between-within" class="quarto-float quarto-figure quarto-figure-center anchored" width="192">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-illustration-comparison-between-within-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06_token_level_predictors_files/figure-html/fig-illustration-comparison-between-within-1.png" id="fig-illustration-comparison-between-within" class="img-fluid figure-img" width="192">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-illustration-comparison-between-within-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.4
</figcaption>
</figure>
</div>
</div></div></div>
</section>
</section>
<section id="within--and-between-comparisons-illustration-using-the-ing-data" class="level2 page-columns page-full" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="within--and-between-comparisons-illustration-using-the-ing-data"><span class="header-section-number">7.4</span> Within- and between-comparisons: Illustration using the ING data</h2>
<p>Let us consider the token-level predictor Following Context. To keep the following illustration simple, we will first reduce this variable to a binary distinction between contexts favorable to -ing (pause, velar), and contexts favorable to -in (coronal, other). In the next section, we will represent all four contexts.</p>
<section id="composition-of-clusters-1" class="level3 page-columns page-full" data-number="7.4.1">
<h3 data-number="7.4.1" class="anchored" data-anchor-id="composition-of-clusters-1"><span class="header-section-number">7.4.1</span> Composition of clusters</h3>
<p>Let us start by looking at the composition of clusters with regard to phonetic context. Recall that it only makes sense to distinguish level-specific patterns if there is variation in the composition of clusters. Thus, words might differ in their distribution across favorable and unfavorable contexts – that is, some words may occur more often in favorable contexts. For speakers, a similar situation may hold: Some speakers may happen to produce a higher number of tokens in favorable contexts than others. Whereas it is reasonable to consider variation among speakers as an unsystematic, erratic feature of the data, we would in fact expect systematic differences between words, perhaps because of their word class or their collocational preferences.</p>
<p><a href="#fig-ing-composition" class="quarto-xref">Figure&nbsp;<span>7.5</span></a> shows the variation in composition among speakers and words. First, we note that, in general, the distribution of tokens in the data set is clearly inclined towards unfavorable contexts. For speakers, we observe variation in composition from close to 0 to about 30 percent of tokens in favorable contexts. For words, the variation is larger. Note that we are only showing items here that occur at least 10 times in the data. Further, we have varied the fill color of the data points to give a rough reflection of the word-specific token count. Compositions represented with lighter fill colors show an increasing susceptibility to sampling variation – that is, their composition may not have been estimated with great precision.</p>
<div class="cell page-columns page-full">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-ing-composition" class="quarto-float quarto-figure quarto-figure-center anchored" width="192">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ing-composition-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06_token_level_predictors_files/figure-html/fig-ing-composition-1.png" id="fig-ing-composition" class="img-fluid figure-img" width="192">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-ing-composition-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.5
</figcaption>
</figure>
</div>
</div></div></div>
<p>(ref:tab-ing-foll-cont-SDs) Token-level predictor : Variation between and within clusters.</p>
<div class="cell">
<div class="cell-output-display">

</div>
</div>
<p>To offer a more complete summary of these components of variation, let us consider the set of standard deviations. The overall SD is at 0.38, the within SD at 0.24. We have a between SD for each clustering variable: For Speaker, the between cluster variability is much smaller than for Item (0.05 vs.&nbsp;0.13).</p>
</section>
<section id="within-cluster-differences-1" class="level3 page-columns page-full" data-number="7.4.2">
<h3 data-number="7.4.2" class="anchored" data-anchor-id="within-cluster-differences-1"><span class="header-section-number">7.4.2</span> Within-cluster differences</h3>
<p>Since we have two clustering factors (Speaker and Item), there are, in principle, two kinds of clusters that we can consider for within-cluster comparisons. Let us compute, for each cluster, a simple difference, between the share of ing in favorable vs.&nbsp;unfavorable contexts. This gives us, for each clustering variable, a distribution of within-differences. These distributions are shown in <a href="#fig-ing-crude-within" class="quarto-xref">Figure&nbsp;<span>7.6</span></a>. For words, we restrict our attention to types that occur at least 5 times in the corpus.</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-ing-crude-within" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" width="480">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-ing-crude-within-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06_token_level_predictors_files/figure-html/fig-ing-crude-within-1.png" id="fig-ing-crude-within" class="img-fluid figure-img" width="480">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig quarto-uncaptioned margin-caption" id="fig-ing-crude-within-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.6
</figcaption>
</figure>
</div>
</div>
</div>
<p>For speakers, differences range between -.10 and +.50, with an average of about 0.17. We interpret this as the average within-word difference in proportion ing between favorable and unfavorable contexts. For words, the distribution of differences is wider, with an average of 0.06. What the shows are crude estimates of the within-cluster differences. The within-effect can be interpreted as the difference in the proportion of ing between contexts (coronal, other, pause, velar) for a given word.</p>
</section>
<section id="between-cluster-differences-1" class="level3 page-columns page-full" data-number="7.4.3">
<h3 data-number="7.4.3" class="anchored" data-anchor-id="between-cluster-differences-1"><span class="header-section-number">7.4.3</span> Between-cluster differences</h3>
<p>Next, let us plot the cluster-specific proportion of -ing against the cluster-specific percentage of tokens in favorable contexts. We would expect to see an association that is consistent with the within-cluster differences we observed above. We will use a <em>bubble chart</em> to show the data, to bring into view the different cluster sizes.</p>
<p>In <a href="#fig-ing-words-between-distribution" class="quarto-xref">Figure&nbsp;<span>7.7</span></a>, each circle represent a cluster. The size of the circle is proportional to the number of tokens for a specific cluster. For Speaker, cluster sizes do not vary much (cf. <a href="03_data_structure.html#fig-ing-tokens-per-speaker" class="quarto-xref">Figure&nbsp;<span>4.1</span></a>). For the clustering variable Item, however, the skewed distribution of token counts (cf. <a href="03_data_structure.html#fig-ing-tokens-per-item" class="quarto-xref">Figure&nbsp;<span>4.2</span></a>) surfaces in “bubbles” of widely varying size.</p>
<p>Let us consider the patterns in the plots. The dotted trend lines represent the model-based within-comparison. Looking at the distribution of points for speakers, it is difficult to make out a pattern in the plot. The between-pattern is summarized by a solid trend line, which seems to be dominated by a handful of speakers sitting at the extremes with respect to both the share of favorable contexts and the overall proportion of ing. Since the cluster compositions are probably the result of chance fluctuations, we should hesitate to “believe” the trend line. The fact that the trend is reversed compared to the within-pattern also raises doubts.</p>
<p>For words, on the other hand, the distribution of points seems to be summarized quite well by the solid trend line: Words that have a stronger tendency to occur in favorable contexts also have a higher share of -ing, on average. The directionality of this pattern is consistent with the observed within-cluster differences.</p>
<div class="cell page-columns page-full">
<div class="cell-output cell-output-stderr">
<pre><code>Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.
ℹ Please use `linewidth` instead.</code></pre>
</div>
<div class="cell-output cell-output-stderr">
<pre><code>Warning: The following aesthetics were dropped during statistical transformation: size.
ℹ This can happen when ggplot fails to infer the correct grouping structure in
  the data.
ℹ Did you forget to specify a `group` aesthetic or to convert a numerical
  variable into a factor?
The following aesthetics were dropped during statistical transformation: size.
ℹ This can happen when ggplot fails to infer the correct grouping structure in
  the data.
ℹ Did you forget to specify a `group` aesthetic or to convert a numerical
  variable into a factor?</code></pre>
</div>
<div class="cell-output-display page-columns page-full">
<div id="fig-ing-words-between-distribution" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" width="422.4">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-ing-words-between-distribution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06_token_level_predictors_files/figure-html/fig-ing-words-between-distribution-1.png" id="fig-ing-words-between-distribution" class="img-fluid figure-img" width="422">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig quarto-uncaptioned margin-caption" id="fig-ing-words-between-distribution-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.7
</figcaption>
</figure>
</div>
</div>
</div>
<p>For Item, the between-trend is steeper than the within-trend. This indicates that the between-pattern is unlikely to be purely compositional. A multilevel regression model can represent these two curves with different coefficients, which allows us to compare numbers reflecting the steepness of the trend lines. In the present case, they are perceptibly different – the between-word difference is larger than the within-word difference.<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a> This means that an association between the composition of words and the outcome quantity persists once the estimates are adjusted for within-differences linked to the token-level predictor. This discrepancy may represent a <em>contextual effect</em>. As we will discuss further below, the interpretation of divergent between- and within-differences as contextual effects hinges on a number of causal assumptions. Importantly, however, the existence of a contextual effect also needs to make sense on linguistic grounds.</p>
<div class="no-row-height column-margin column-container"><div id="fn12"><p><sup>12</sup>&nbsp;This is also reflected in the amount by which the random intercept SD decreases: Including the token-level predictor into the model leads to only a minor decrease, since the variability among words when account is taken of composition almost remains unchanged. In other words, the residual variation among words that is independent of contextual make-up. As mentioned above, a useful measure is the ratio of the random intercept variance before/after adjusting for level-1 covariates <span class="citation" data-cites="Bingenheimer_Raudenbush2004">(<a href="references.html#ref-Bingenheimer_Raudenbush2004" role="doc-biblioref">Bingenheimer and Raudenbush 2004</a>: p.&nbsp;61)</span>.</p></div></div></section>
</section>
<section id="interpretation-of-between-and-within-comparisons" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="interpretation-of-between-and-within-comparisons"><span class="header-section-number">7.5</span> Interpretation of between and within comparisons</h2>
<p>Before we go about splitting between- and within patterns, and attaching different interpretations to each, we need to be convinced that differences in composition really exist among clusters. There are two sources of information we can rely on: our subject-matter knowledge and the information in the data. As for empirical hints about the reality of compositional variation, we can look at the amount of between-cluster variation, which is reflected in the between-SD, compared with the within-.cluster variation. We could also attempt an inferential assessment, asking whether a variance component representing between-cluster variability improves model fit. Ultimately, however, we should think about whether it makes sense for clusters to vary in their distribution of token-level predictors. In our case, it seems difficult to explain why speakers should vary systematically in terms of the kinds of contexts in which they use words ending in -ing. For words, however, it does not take much to convince ourselves that there are real differences among words. These linguistic assessments find support in the descriptive assessments of the between-cluster SDs: Variation among words is greater than among speakers (0.13 vs.&nbsp;0.05), the latter being quite small. We will therefore focus on potential contextual differences for Item.</p>
<p>The interpretation of differences in within and between comparisons greatly depends on the underlying subject matter. It seems, however, that we would need a convincing story for why contextual differences should exist.</p>
<p>The story of trying and going…</p>
<p>We can formalize and check the coherence of our story using agent-based modeling.</p>
<p>A look at the literature also shows that disciplines differ in the emphasis they attach to these two types of comparisons. Some consider within-comparisons as the primary target of inference. This is often the case in econometrics or public policy, where interest lies in isolating the effect of different potential interventions at the level of the individual (the level-1 unit in these settings). This is because relevant decisions are made by individuals. In other research traditions, contextual effects are of substantive interest. Examples are education and public health.</p>
<p>Interpretation of compositional effects: We probably wouldn’t go as far as saying that, in cases where differences between words reduce to the compositional effect, the observed between-word differences are an artefact of differences in token-level composition. This is because the make-up is part of the word.</p>
</section>
<section id="model-specification-for-between-and-within-comparisons" class="level2 page-columns page-full" data-number="7.6">
<h2 data-number="7.6" class="anchored" data-anchor-id="model-specification-for-between-and-within-comparisons"><span class="header-section-number">7.6</span> Model specification for between and within comparisons</h2>
<p>A multilevel model allows us to decompose the association between a token-level predictor and the outcome into level-specific components. To make this split, the model must include cluster means for token-level variables as an additional level-2 variable. This means that, prior to modeling, we need to construct derived variables that represent cluster composition. This will always be some sort of cluster-specific average. For a quantitative predictor, it is the average over all tokens. For a binary predictor, it depends on how the variable is coded. Since all variables are coded in some numeric form, we still take an averge (e.g.&nbsp;over indicator dummy variables 0 and 1, or over sum contrasts -1 and +1).<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a> We will refer to these derived variables as <em>cluster means</em>.</p>
<div class="no-row-height column-margin column-container"><div id="fn13"><p><sup>13</sup>&nbsp;The same is true for a categorical variable with <span class="math inline">\(k\)</span> levels, where we average over each of the <span class="math inline">\(k - 1\)</span> contrast variables.</p></div></div><p>For token-level variables whose cluster-means are included in the model, the model will return information about the relationship at two levels. What complicates matters slightly is that we now have two options for how the token-level predictor itself should be coded. There are two options. While these options essentially produce identical analyses, and produce the same coefficients for within-cluster comparisons, they return <em>different</em> coefficients for between-cluster comparisons. Somewhat counter-intuitively, then, the way in which we code the token-level predictor affects the meaning and interpretation of the between-cluster comparison.</p>
<section id="model-specification-two-options" class="level3 page-columns page-full" data-number="7.6.1">
<h3 data-number="7.6.1" class="anchored" data-anchor-id="model-specification-two-options"><span class="header-section-number">7.6.1</span> Model specification: Two options</h3>
<p>Let us first look at these two options and then consider differences in meaning. First, we can simply include the token-level predictor in its <em>original form</em>, i.e.&nbsp;without making any changes to it. The second option is to include a <em>cluster-mean centered</em> version of it. Token-level predictor values are then represented as deviations from their cluster-specific means.<a href="#fn14" class="footnote-ref" id="fnref14" role="doc-noteref"><sup>14</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn14"><p><sup>14</sup>&nbsp;They are therefore also called <em>mean-deviation variables</em>, or <em>de-meaned variables</em>, or <em>within-group deviation scores</em>. The procedure is sometimes called <em>within-group centering</em> or <em>centering within context</em>.</p></div><div id="fn15"><p><sup>15</sup>&nbsp;The label <em>between-within model</em> appears to be due to <span class="citation" data-cites="Sjölander_etal2013">Sjölander et al. (<a href="references.html#ref-Sjölander_etal2013" role="doc-biblioref">2013</a>)</span>; this form is also referred to as the <em>hybrid model</em> <span class="citation" data-cites="Allison2009">(<a href="references.html#ref-Allison2009" role="doc-biblioref">Allison 2009, 23</a>)</span>. The <em>Mundlak model</em> is named after <span class="citation" data-cites="Mundlak1978">(<a href="references.html#ref-Mundlak1978" role="doc-biblioref">Mundlak 1978</a>)</span>; it is also referred to as the <em>correlated random effects model</em> <span class="citation" data-cites="Wooldridge2010 Cameron_Trivedi2005">(<a href="references.html#ref-Wooldridge2010" role="doc-biblioref">Wooldridge 2010, 286</a>; <a href="references.html#ref-Cameron_Trivedi2005" role="doc-biblioref">Cameron and Trivedi 2005, 786</a>)</span> or the <em>including-the-group-means approach</em> <span class="citation" data-cites="Castellano_etal2014">(<a href="references.html#ref-Castellano_etal2014" role="doc-biblioref">Castellano, Rabe-Hesketh, and Skrondal 2014, 335</a>)</span>.</p></div></div><p>Along with its cluster means, a token-level predictor can therefore enter the model in its original form or its cluster-mean centered form. These formulations are referred to as the the <em>Mundlak model</em> (with the token-level predictor in its original form) <em>between-within model</em> (with the token-level predictor in its cluster-mean centered form).<a href="#fn15" class="footnote-ref" id="fnref15" role="doc-noteref"><sup>15</sup></a> To reiterate, choosing between these two options has no effect on the within-cluster estimate; however, the meaning of the between-cluster coefficients will differ:</p>
<ul>
<li>Between-within model: Including the <em>cluster-mean centered</em> version of the token-level predictor will produce an estimate of the <em>between-cluster comparison</em>. In <a href="#fig-ing-words-between-distribution" class="quarto-xref">Figure&nbsp;<span>7.7</span></a>) above, this is the slope of the between-cluster trend line.</li>
<li>Mundlak model: Using the <em>original form</em> of the token-level predictor returns and estimate of the <em>difference of the between-estimate and the within-estimate</em>. In <a href="#fig-ing-words-between-distribution" class="quarto-xref">Figure&nbsp;<span>7.7</span></a>), this is the differences between the two slopes. In that case, it signals how much steeper the between-trend is. Note that this differences corresponds to what is meant by a <em>contextual effect</em>. To obtain the between-cluster comparison, we have to add the two coefficients.<a href="#fn16" class="footnote-ref" id="fnref16" role="doc-noteref"><sup>16</sup></a>.</li>
</ul>
<div class="no-row-height column-margin column-container"><div id="fn16"><p><sup>16</sup>&nbsp;See <span class="citation" data-cites="Raudenbush_Bryk2002">Raudenbush and Bryk (<a href="references.html#ref-Raudenbush_Bryk2002" role="doc-biblioref">2002</a>)</span>, p.&nbsp;140; <span class="citation" data-cites="Rabe-Hesketh_Skrondal2022">Rabe-Hesketh and Skrondal (<a href="references.html#ref-Rabe-Hesketh_Skrondal2022" role="doc-biblioref">2021</a>)</span>, p.&nbsp;171</p></div></div><p>Here are the two model formulations in math notation: <span class="math display">\[
\begin{aligned}
y_{ij} &amp;= \bar\alpha + \alpha_j + \beta^{\textrm{B}}\bar{x}_j + \beta^{\textrm{W}}(x_{ij}-\bar{x}_j) &amp;&amp; \text{Between-within model} \\
y_{ij} &amp;= \bar\alpha + \alpha_j + \beta^{\textrm{C}}\bar{x}_j + \beta^{\textrm{W}}x_{ij} &amp;&amp; \text{Mundlak model}
\end{aligned}
\]</span></p>
<p>These two formulations yield identical estimates for within-comparisons - hence the identical label <span class="math inline">\(\beta^{\textrm{W}}\)</span>. The interpretation of the other coefficient differs, however: The between-within model returns the between-estimator <span class="math inline">\(\beta^{\textrm{B}}\)</span> and the Mundlak model returns the contextual difference <span class="math inline">\(\beta^{\textrm{C}}\)</span> (i.e.&nbsp;<span class="math inline">\(\beta^{\textrm{B}} - \beta^{\textrm{W}}\)</span>). In general, then, there is a simple relationship between these coefficients: <span class="math inline">\(\beta^{\textrm{B}} = \beta^{\textrm{W}} + \beta^{\textrm{C}}\)</span>, or, equivalently, <span class="math inline">\(\beta^{\textrm{C}} = \beta^{\textrm{B}} - \beta^{\textrm{W}}\)</span>.</p>
<p>The meaning signaled by <span class="math inline">\(\beta^{\textrm{C}}\)</span> is the change in outcome expected for a level-1 (a token) moving from one level-2 unit (i.e.&nbsp;word) to another. In our case, how does the probability of ing change for a specific token in the same context (i.e.&nbsp;with the same following context) if it occurs in another word which differs from the original word in composition only. The specific context in which the token occurs stays the same. <span class="math inline">\(\beta^{\textrm{B}}\)</span>, on the other hand, gives the expected change in the probability of observing ing when changing from one word to another word that differs in composition, without holding constant the specific context in which a word occurs. <span class="math inline">\(\beta^{\textrm{B}}\)</span> therefore includes the token-level within-effect.</p>
</section>
<section id="choosing-between-the-two-specifications" class="level3 page-columns page-full" data-number="7.6.2">
<h3 data-number="7.6.2" class="anchored" data-anchor-id="choosing-between-the-two-specifications"><span class="header-section-number">7.6.2</span> Choosing between the two specifications</h3>
<p>If we understand which meaning is signaled by the coefficient attaching to the derived level-2 cluster-mean variable (i.e.&nbsp;<span class="math inline">\(\beta^{\textrm{B}}\)</span> or <span class="math inline">\(\beta^{\textrm{C}}\)</span>), there is little to choose between these two formulations. [Bell_etal2019, p.&nbsp;1056] mention computational advantages of the between-within-specification.<a href="#fn17" class="footnote-ref" id="fnref17" role="doc-noteref"><sup>17</sup></a> Which of the interpretations is more meaningful in substantive terms depends on the subject-matter context [see Bell_etal2019, p.&nbsp;1056]. In some settings, it may not make sense to think of level-1 tokens as being able to change cluster membership. Then, the direct interpretation of <span class="math inline">\(\beta^{\textrm{C}}\)</span> may not be directly meaningful. However, thinking of a token as being able to change cluster membership doesn’t seem too problematic for language data.</p>
<div class="no-row-height column-margin column-container"><div id="fn17"><p><sup>17</sup>&nbsp;This is because cluster means and cluster-mean centered scores are uncorrelated.</p></div></div><p>On the other hand, it is sometimes argued that <span class="math inline">\(\beta^{\textrm{B}}\)</span> offers a blend of two components that should be kept apart for interpretation. Thus, <span class="citation" data-cites="Begg_Parides2003">(<a href="references.html#ref-Begg_Parides2003" role="doc-biblioref">Begg and Parides 2003, 2598–99</a>)</span> argue in favor of the Mundlak specification since they consider <span class="math inline">\(\beta^{\textrm{B}}\)</span> in the between-within model to be vulnerable to misinterpretation. This is because it mixes two differences, the between- and the within-difference. The usual interpretation of regression coefficients as a change in the outcome associated with a one-unit increase in one specific predictor does not apply to <span class="math inline">\(\beta^{\textrm{B}}\)</span>, which signals the expected change in the outcome associated with a one-unit increase on <em>both</em> the within-cluster and the between-cluster level. Since we usually do not interpret coefficients but rather use model-based visualizations, we do not have a strong general position here.</p>
<p>Another advantage of the Mundlak formulation is that it returns <span class="math inline">\(\beta^{\textrm{C}}\)</span> as an estimate of the difference of within- and between-patterns. On this scale, zero is an informative value, since it represents the absence of a contextual difference, i.e.&nbsp;the situation where between-cluster differences are due to differences in composition. The statistical uncertainty surrounding <span class="math inline">\(\beta^{\textrm{C}}\)</span> permits the data to comment on the question whether there are contextual differences over and above compositional differences.<a href="#fn18" class="footnote-ref" id="fnref18" role="doc-noteref"><sup>18</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn18"><p><sup>18</sup>&nbsp;This statistical assessment is of course also possible with the between-within model, but here this information is in the difference between two coefficients and therefore does not appear in the regression table.</p></div></div><p>A point that seems to have received less attention is the setting of cross-classified clustering structures, what may be particularly relevant for language data settings. The between-within specification would require us to derive <em>cluster-mean centered</em> variables with reference to two types of cluster membership. It is not immediately clear what such a centered variable should look like. The Mundlak model, in contrast, extends directly to cross-classified clustering factors: We can include the original token-level predictor along with two sets of cluster means – one for speakers, and one for words.</p>
</section>
<section id="failure-to-partition-between--and-within-differences" class="level3 page-columns page-full" data-number="7.6.3">
<h3 data-number="7.6.3" class="anchored" data-anchor-id="failure-to-partition-between--and-within-differences"><span class="header-section-number">7.6.3</span> Failure to partition between- and within-differences</h3>
<p>Let us compare the Mundlak and the between-within model to a multilevel model that does not include cluster means for the token-level predictor <span class="math inline">\(x_{ij}\)</span>: <span class="math display">\[
y_{ij} = \bar\alpha + \alpha_j + \beta^*x_{ij}
\]</span></p>
<p>If we do not partition token-level predictors into a between-cluster and a within-cluster component, a multilevel model will return a comparison that blends both differences. Thus, a model that does not include cluster means will not distinguish between <span class="math inline">\(\beta^{\textrm{W}}\)</span> and <span class="math inline">\(\beta^{\textrm{C}}\)</span> (or <span class="math inline">\(\beta^{\textrm{B}}\)</span>). Instead, we will obtain the coefficient <span class="math inline">\(\beta^*\)</span>, which is intermediate between <span class="math inline">\(\beta^{\textrm{W}}\)</span> and <span class="math inline">\(\beta^{\textrm{B}}\)</span>. More specifically, <span class="math inline">\(\beta^*\)</span> is a weighted average of for <span class="math inline">\(\beta^{\textrm{W}}\)</span> and <span class="math inline">\(\beta^{\textrm{B}}\)</span>, with the weights proportional to the precision of each (as reflected in their standard error). The combined estimate is closer to the difference that is estimated with greater precision, which is the within-difference <span class="citation" data-cites="Rabe-Hesketh_Skrondal2022">(See <a href="references.html#ref-Rabe-Hesketh_Skrondal2022" role="doc-biblioref">Rabe-Hesketh and Skrondal 2021, 164–65</a>)</span>. Here is the relationship between <span class="math inline">\(\beta^*\)</span>, <span class="math inline">\(\beta^{\textrm{B}}\)</span>, and <span class="math inline">\(\beta^{\textrm{W}}\)</span> <span class="citation" data-cites="Raudenbush_Bryk2002">(see <a href="references.html#ref-Raudenbush_Bryk2002" role="doc-biblioref">Raudenbush and Bryk 2002, 138–39</a>)</span>: <span class="math display">\[
\begin{aligned}
\beta^* &amp;= \frac{w_{\textrm{W}} \beta^{\textrm{W}} + w_{\textrm{B}} \beta^{\textrm{B}}}{w_{\textrm{W}} + w_{\textrm{B}}} &amp;&amp; \text{Precision-weighted estimate for } \beta^*  \\
w_{\textrm{W}} &amp;= \frac{1}{(SE_{\beta^{\textrm{W}}})^2} &amp;&amp; \text{Weight for within-component} \\
w_{\textrm{B}} &amp;= \frac{1}{(SE_{\beta^{\textrm{B}}})^2} &amp;&amp; \text{Weight for between-component} \\
SE_{\beta^*} &amp;= \sqrt{\frac{1}{w_{\textrm{W}} + w_{\textrm{B}}}} &amp;&amp; \text{Standard error for } \beta^*
\end{aligned}
\]</span></p>
<p>By blending relationships at two levels, <span class="math inline">\(\beta^*\)</span> usually has no direct interpretation <span class="citation" data-cites="Raudenbush_Bryk2002">(<a href="references.html#ref-Raudenbush_Bryk2002" role="doc-biblioref">Raudenbush and Bryk 2002, 138</a>)</span>. If the between- and within-differences were very similar, however, <span class="math inline">\(\beta^*\)</span> does reflect an interpretable comparison.<a href="#fn19" class="footnote-ref" id="fnref19" role="doc-noteref"><sup>19</sup></a> To guard against inappropriately blending between- and within-comparisons, we can separate these comparisons in our multilevel model specification.<a href="#fn20" class="footnote-ref" id="fnref20" role="doc-noteref"><sup>20</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn19"><p><sup>19</sup>&nbsp;This estimator has the additional advantage of being more efficient, i.e.&nbsp;yielding higher precision than alternative approaches that isolate the between- and within-components. This is because it combines information from two sources. See <span class="citation" data-cites="Bell_etal2019 Rabe-Hesketh_Skrondal2022">(<a href="references.html#ref-Bell_etal2019" role="doc-biblioref">Bell, Fairbrother, and Jones 2019, 1057</a>; <a href="references.html#ref-Rabe-Hesketh_Skrondal2022" role="doc-biblioref">Rabe-Hesketh and Skrondal 2021, 165</a>)</span>.</p></div><div id="fn20"><p><sup>20</sup>&nbsp;There is also a “test” for such situations, the Hausman test <span class="citation" data-cites="Hausman1978">(<a href="references.html#ref-Hausman1978" role="doc-biblioref">Hausman 1978</a>)</span>.</p></div></div></section>
<section id="example-following-context" class="level3 page-columns page-full" data-number="7.6.4">
<h3 data-number="7.6.4" class="anchored" data-anchor-id="example-following-context"><span class="header-section-number">7.6.4</span> Example: Following context</h3>
<p>For a concrete example, consider the token-level predictor Following Context. <span class="citation" data-cites="tab-ing-b-bW-bB">(<a href="references.html#ref-tab-ing-b-bW-bB" role="doc-biblioref"><strong>tab-ing-b-bW-bB?</strong></a>)</span> reports estimates from three different models. A multilevel model without cluster means returns <span class="math inline">\(\beta^*\)</span>, the conflated comparison. This difference is a weighted average of <span class="math inline">\(\beta^{\textrm{W}}\)</span> and <span class="math inline">\(\beta^{\textrm{B}}\)</span>, the coefficients reported by the between-within model. <span class="math inline">\(\beta^*\)</span> is closer to <span class="math inline">\(\beta^{\textrm{W}}\)</span>, the estimate with the smaller standard error (i.e.&nbsp;greater precision).</p>
<div class="cell">
<div class="cell-output-display">

</div>
</div>
<p><a href="#fig-ing-b-bW-bB" class="quarto-xref">Figure&nbsp;<span>7.8</span></a> illustrates the relationship between the three estimates graphically. Each density curve represents a coefficients. The dispersion of the curve reföects the statistical uncertainty surrounding each estimate. We can see clearly that <span class="math inline">\(\beta^*\)</span> is drawn heavily towards the more precise estimate of <span class="math inline">\(\beta^{\textrm{W}}\)</span>.</p>
<div class="cell page-columns page-full">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-ing-b-bW-bB" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-ing-b-bW-bB-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06_token_level_predictors_files/figure-html/fig-ing-b-bW-bB-1.png" class="img-fluid figure-img" width="192">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig" id="fig-ing-b-bW-bB-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.8: β* as the precision-weighted average over β<sup>W</sup> and β<sup>B</sup>.
</figcaption>
</figure>
</div>
</div></div></div>
</section>
<section id="simulation" class="level3 page-columns page-full" data-number="7.6.5">
<h3 data-number="7.6.5" class="anchored" data-anchor-id="simulation"><span class="header-section-number">7.6.5</span> Simulation</h3>
<p>In our illustrative data set, <span class="math inline">\(\beta^*\)</span> ended up being quite close to <span class="math inline">\(\beta^{\textrm{W}}\)</span>, in which case concerns about bias are somewhat alleviated. <span class="math inline">\(\beta^*\)</span> will usually be closer to <span class="math inline">\(\beta^{\textrm{W}}\)</span>, since this coefficient is typically estimated with higher precision. To form some intuition about the factors influencing the amount of bias in <span class="math inline">\(\beta^*\)</span>, let us run a simulation study. The amount by which <span class="math inline">\(\beta^*\)</span> deviates from <span class="math inline">\(\beta^{\textrm{W}}\)</span> depends on the relative precision of <span class="math inline">\(\beta^{\textrm{W}}\)</span> and <span class="math inline">\(\beta^{\textrm{B}}\)</span>. We will vary three parameters: The number of tokens per cluster, the number of clusters, and the random intercept SD for the clusters.</p>
<p><a href="#fig-ing-b-bW-bB" class="quarto-xref">Figure&nbsp;<span>7.8</span></a> shows the results of our simulation. The limits of the vertical axis denote the locations of the coefficients <span class="math inline">\(\beta^{\textrm{W}}\)</span> (bottom) and <span class="math inline">\(\beta^{\textrm{B}}\)</span> (top). The intermediate value of <span class="math inline">\(\beta^*\)</span> for different simulated values is denoted by points. In both panels, the horizontal axis shows the most important parameter: the number of tokens per cluster. With only 2 tokens per cluster (at the left end of the scale), <span class="math inline">\(\beta^*\)</span> lies roughly half-way in between the coefficients. As the number of tokens per cluster increases, <span class="math inline">\(\beta^{\textrm{W}}\)</span> is estimated with higher precision; as a result, <span class="math inline">\(\beta^*\)</span> approaches <span class="math inline">\(\beta^{\textrm{W}}\)</span>. Panel (a) shows an additional parameter: the number of clusters. With more clusters, the precision of <span class="math inline">\(\beta^{\textrm{B}}\)</span> increases, and <span class="math inline">\(\beta^*\)</span> therefore moves toward <span class="math inline">\(\beta^{\textrm{B}}\)</span>. This influence only surfaces with lower token counts per cluster – at about 50 tokens per cluster, the number of clusters appears to be largely irrelevant under the conditions simulated here. Panel (b) shows the third parameter: the random intercept SD for clusters. As the variation among clusters decreases, <span class="math inline">\(\beta^{\textrm{B}}\)</span> is estimated with higher precision and therefore exerts more pull on <span class="math inline">\(\beta^*\)</span>. With our current simulation settings, this influence is only felt for large numbers of tokens per cluster.</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-sim-b-bW-bB" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" width="422.4">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-sim-b-bW-bB-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06_token_level_predictors_files/figure-html/fig-sim-b-bW-bB-1.png" id="fig-sim-b-bW-bB" class="img-fluid figure-img" width="422">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig quarto-uncaptioned margin-caption" id="fig-sim-b-bW-bB-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.9
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="causal-assumptions-for-the-identification-of-contextual-effects" class="level2 page-columns page-full" data-number="7.7">
<h2 data-number="7.7" class="anchored" data-anchor-id="causal-assumptions-for-the-identification-of-contextual-effects"><span class="header-section-number">7.7</span> Causal assumptions for the identification of contextual effects</h2>
<p>The interpretation of a difference in within- and between-coefficients as a contextual effect hinges on the absence of confounding. Unobserved confounders with an arrow pointing into X and Y can sit at level 2 (a word-level confounder) or at level 1 (a token-level confounder). These two scenarios are shown in <a href="#fig-dag-within-between-endogeneity" class="quarto-xref">Figure&nbsp;<span>7.10</span></a>, where variables are arranged by the level at which they are measured: Level-1 variables appear at the bottom, level-2 variables at the top.</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-dag-within-between-endogeneity" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" width="422.4">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-dag-within-between-endogeneity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06_token_level_predictors_files/figure-html/fig-dag-within-between-endogeneity-1.png" id="fig-dag-within-between-endogeneity" class="img-fluid figure-img" width="422">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig quarto-uncaptioned margin-caption" id="fig-dag-within-between-endogeneity-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.10
</figcaption>
</figure>
</div>
</div>
</div>
<section id="token-level-confounding" class="level3" data-number="7.7.1">
<h3 data-number="7.7.1" class="anchored" data-anchor-id="token-level-confounding"><span class="header-section-number">7.7.1</span> Token-level confounding</h3>
<p>There is no easy fix for token-level confounding. It requires some form of instrumental-variables approach.</p>
</section>
<section id="cluster-level-confounding" class="level3 page-columns page-full" data-number="7.7.2">
<h3 data-number="7.7.2" class="anchored" data-anchor-id="cluster-level-confounding"><span class="header-section-number">7.7.2</span> Cluster-level confounding</h3>
<p>One assumption is that there are no unobserved word-level confounders, i.e.&nbsp;word-level predictors that have a causal effect on both X (the token-level predictor) and Y. A situation that would distort our estimates is shown in <a href="#fig-dag-within-between-endogeneity" class="quarto-xref">Figure&nbsp;<span>7.10</span></a> a, where U is the unobserved word-level confounder. We will refer to this situation as <em>word-level unobserved confounding</em> or <em>word-level omitted variable bias</em>. In the econometrics literature, this situation is called <em>level-2 endogeneity</em>.<a href="#fn21" class="footnote-ref" id="fnref21" role="doc-noteref"><sup>21</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn21"><p><sup>21</sup>&nbsp;In that literature, endogeneity (i.e.&nbsp;unobserved confounding) is often described as a correlation between the predictor in question (here the token-level predictor) and an error term (here, the random intercept for word). The correlation arises because the error term contains the effects of unobserved confounders - thus, the word-level intercept reflects unobserved word-level predictors. This correlation is a consequence of the omitting a confounder. To make sense of the econometrics literature, we can establish the following mapping: level-2 endogeneity = correlation between predictor and random intercept = omitted variable bias due to unobserved level-2 confounder.</p></div><div id="fn22"><p><sup>22</sup>&nbsp;Another viable option, which is commonly referred to as the fixed-effects approach, is to include the individual cluster as fixed (instead of random) intercepts. See <span class="citation" data-cites="Bell_etal2019">Bell, Fairbrother, and Jones (<a href="references.html#ref-Bell_etal2019" role="doc-biblioref">2019</a>)</span>; <span class="citation" data-cites="Rabe-Hesketh_Skrondal2022">Rabe-Hesketh and Skrondal (<a href="references.html#ref-Rabe-Hesketh_Skrondal2022" role="doc-biblioref">2021</a>)</span>, p.&nbsp;162</p></div></div><p>In such cases, the within-comparison can be consistently estimated by including mX, the cluster means of the token-level variable, as an additional predictor.<a href="#fn22" class="footnote-ref" id="fnref22" role="doc-noteref"><sup>22</sup></a> The resulting DAG is shown in <a href="#fig-dag-within-between-identified-within" class="quarto-xref">Figure&nbsp;<span>7.11</span></a>. X denotes the token-level predictor, and mX the derived cluster means. These are shown on level 2, since they are cluster attributes. The dotted line connecting X and mX indicates the intrinsic link between the variables: mX is a <em>derived variable</em>, a summary measure of a token-level predictor.</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-dag-within-between-identified-within" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" width="422.4">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-dag-within-between-identified-within-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06_token_level_predictors_files/figure-html/fig-dag-within-between-identified-within-1.png" id="fig-dag-within-between-identified-within" class="img-fluid figure-img" width="422">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig quarto-uncaptioned margin-caption" id="fig-dag-within-between-identified-within-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.11
</figcaption>
</figure>
</div>
</div>
</div>
<p>Adjusting for mX effectively closes the backdoor path from U into X. This is not immediately clear from our knowledge about conditional independencies in DAGs. We need new heuristics for denoting derived cluster means in a DAG. Since the value of a level-2 confounder U is constant across all tokens in a certain cluster, the influence of U on X will surface at the level of the cluster. The derived cluster means mX therefore block the causal effect a level-2 confounder has on X. By adjusting for mX, we are therefore able to remove the confounding bias from the within-effect, i.e.&nbsp;the arrow pointing from X into Y. This means that within-effects are identified. As <a href="#fig-dag-within-between-identified-within" class="quarto-xref">Figure&nbsp;<span>7.11</span></a> b illustrates, the bias is assigned to mX. Now, only the effect of mX on Y is confounded by U.</p>
<p>For word-level unobserved confounding, here are the requirements for consistent estimation of our comparisons: (i) for <span class="math inline">\(\beta^*\)</span>, we need to adjust for U; (ii) for <span class="math inline">\(\beta^{\textrm{W}}\)</span>, we need to adjust for mX; and (iii) for <span class="math inline">\(\beta^{\textrm{B}}\)</span>, we need to adjust for U. If U is indeed unobserved, standard regression modeling can only arrive at consistent estimates of <span class="math inline">\(\beta^{\textrm{W}}\)</span>. All other parameters remain biased. Importantly, this bias propagates to the estimation of other cluster-level (i.e.&nbsp;level-2) predictors as well as cluster-specific parameters (e.g.&nbsp;random intercepts) and their associated hyperparameters (e.g.&nbsp;random intercept SD). These estimates remain biased even after adjusting for mX. This means that the between-comparison will still be confounded with the omitted level-2 predictors and therefore still be biased. <span class="citation" data-cites="Rabe-Hesketh_Skrondal2022">(See <a href="references.html#ref-Rabe-Hesketh_Skrondal2022" role="doc-biblioref">Rabe-Hesketh and Skrondal 2021, 165</a>)</span>.</p>
<p>The econometrics literature therefore cautions against using random effects when exogeneity assumptions are not met. Fixed-effects regression is recommended as an alternative approach.<a href="#fn23" class="footnote-ref" id="fnref23" role="doc-noteref"><sup>23</sup></a> If there is level-2 endogeneity, a fixed-effects model can be used to arrive at consistent estimates of within-differences.<a href="#fn24" class="footnote-ref" id="fnref24" role="doc-noteref"><sup>24</sup></a> For situations such as that depicted in <a href="#fig-dag-within-between-identified-within" class="quarto-xref">Figure&nbsp;<span>7.11</span></a> a, fixed-effects regression (which includes the clustering variable as a factor) returns <em>only</em> <span class="math inline">\(\beta^{\textrm{W}}\)</span>, which is identical to <span class="math inline">\(\beta^{\textrm{W}}\)</span> in the Mundlak or between-within model, i.e.&nbsp;a multilevel regression including cluster means. Since it is a fixed-effects regression, the biased parameters from the random-effects model are simply not estimated. <span class="math display">\[
\begin{aligned}
y_{ij} &amp;\sim \textrm{Normal}(\mu_{ij}, \sigma) \\
\mu_{ij} &amp;= \alpha_j^{\scriptsize{\textrm{FE}}} + \beta^{\textrm{W}}x_{ij} &amp;&amp; \text{Fixed-effects} \\[14pt]
y_{ij} &amp;\sim \textrm{Normal}(\mu_{ij}, \sigma) \\
\mu_{ij} &amp;= \alpha_j^{\scriptsize{\textrm{RE}}} + \beta^*x_{ij} &amp;&amp; \text{Naive multilevel model} \\
\alpha_j^{\scriptsize{\textrm{RE}}} &amp;\sim \textrm{Normal}(0, \sigma_{\alpha}) \\
\bar{\alpha} &amp;= \gamma   + \gamma^{\textrm{G}} G_j \\[14pt]
y_{ij} &amp;\sim \textrm{Normal}(\mu_{ij}, \sigma) \\
\mu_{ij} &amp;= \alpha_j^{\scriptsize{\textrm{RE}}} + \beta^{\textrm{W}}(x_{ij} - \bar{x}_j) &amp;&amp; \text{Mundlak model} \\
\alpha_j^{\scriptsize{\textrm{RE}}} &amp;\sim \textrm{Normal}(\bar{\alpha}, \sigma_{\alpha}) \\
\bar{\alpha} &amp;= \gamma   + \beta^{\textrm{C}} \bar{x}_j   + \gamma^{\textrm{G}} G_j \\[14pt]
y_{ij} &amp;\sim \textrm{Normal}(\mu_{ij}, \sigma) \\
\mu_{ij} &amp;= \alpha_j^{\scriptsize{\textrm{RE}}} + \beta^{\textrm{W}}x_{ij} &amp;&amp; \text{Between-within model} \\
\alpha_j^{\scriptsize{\textrm{RE}}} &amp;\sim \textrm{Normal}(\bar{\alpha}, \sigma_{\alpha}) \\
\bar{\alpha} &amp;= \gamma   + \beta^{\textrm{B}}\bar{x}_j   + \gamma^{\textrm{G}} G_j
\end{aligned}
\]</span></p>
<div class="no-row-height column-margin column-container"><div id="fn23"><p><sup>23</sup>&nbsp;It is sometimes said that fixed-effects and random effects differ in that random effects assume zero correlation between the random effects and observed level-2 predictors (i.e.&nbsp;level-2 exogeneity), while fixed effects permit correlation between fixed effects and observed predictors. A correlation between the random effects and observed covariates reflects omitted variable bias.</p></div><div id="fn24"><p><sup>24</sup>&nbsp;There are two strategies: de-meaning and subject dummies <span class="citation" data-cites="Rabe-Hesketh_Skrondal2022">(See <a href="references.html#ref-Rabe-Hesketh_Skrondal2022" role="doc-biblioref">Rabe-Hesketh and Skrondal 2021, 274–79</a>)</span>.</p></div></div><div class="cell">
<div class="cell-output-display">

</div>
</div>
<p>Using a between-within (or Mundlak) model relaxes the assumption of level-2 exogeneity, i.e.&nbsp;that the random intercept is uncorrelated with the token-level predictor. This leads to consistent estimates for within-differences. <span class="citation" data-cites="Rabe-Hesketh_Skrondal2022">(See <a href="references.html#ref-Rabe-Hesketh_Skrondal2022" role="doc-biblioref">Rabe-Hesketh and Skrondal 2021, 174</a>)</span>. Yet, the estimates for cluster-level predictors and the random intercept SD are not consistently estimated <span class="citation" data-cites="Ebbes_etal2004">(<a href="references.html#ref-Ebbes_etal2004" role="doc-biblioref">Ebbes, Böckenholt, and Wedel 2004, 166</a>)</span>. This is because if the cluster means absorb causal information flowing from level-2 predictors. This means that the between-difference is contaminated by the absorbed information.</p>
<p>In situations where cluster-level unobserved confounding is suspected, the following advice can be given:</p>
<ul>
<li>A multilevel model without cluster means includes absolutely no precautions against bias.</li>
<li>If interest lies exclusively in within-effects, we can use either fixed-effects regression or a multilevel model including cluster means (i.e.&nbsp;a Mundlak or between-within model).</li>
<li>If we are also interested in parameters associated with level 2, we must understand that estimates from a multilevel model including cluster means are likely to be biased: This applies to (i) the random effects themselves, (ii) random effects hyper-parameters, and (iii) estimates for level-2 predictor, including the between-comparison and, alternatively, the contextual effect.</li>
</ul>
<p>In short: Fixed-effects regression is save but limiting, and the naive use of multilevel models may lead to misleading interpretations.</p>
<p>For the ING data, we should therefore be asking whether the apparent contextual effect could reflect cluster-level confounding. Are there any word-level variables that have a causal effect on the response and on the token-level predictor. To rephrase, are there any unobserved word-level confounders that influence both the outcome and the composition of clusters. A candidate is Word Class: g-dropping is sensitive to word class, with verbs and gerunds showing a higher rate of g-dropping. The word class of a token will also have an influence on the Following Context, since word classes surface in different syntactic contexts, and there may be systematic differences in the kinds of words that tend to follow. If this is the case, we would be dealing with cluster-level confounding, or cluster-level omitted variable bias.<a href="#fn25" class="footnote-ref" id="fnref25" role="doc-noteref"><sup>25</sup></a></p>
<div class="no-row-height column-margin column-container"><div id="fn25"><p><sup>25</sup>&nbsp;In the econometrics jargon, we would state that the level-2 exogeneity assumption is violated.</p></div></div></section>
<section id="understanding-bias" class="level3 page-columns page-full" data-number="7.7.3">
<h3 data-number="7.7.3" class="anchored" data-anchor-id="understanding-bias"><span class="header-section-number">7.7.3</span> Understanding bias</h3>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-dag-bias-analysis" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" width="422.4">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-dag-bias-analysis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06_token_level_predictors_files/figure-html/fig-dag-bias-analysis-1.png" id="fig-dag-bias-analysis" class="img-fluid figure-img" width="422">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig quarto-uncaptioned margin-caption" id="fig-dag-bias-analysis-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.12
</figcaption>
</figure>
</div>
</div>
</div>
<p>In setting (a), where there is no contextual effect, <span class="math inline">\(\gamma\)</span>, the coefficient for the cluster-level predictor <span class="math inline">\(W\)</span>, will be biased. The amount of bias in <span class="math inline">\(\gamma\)</span>, denoted as <span class="math inline">\(\delta_\gamma\)</span>, depends on <span class="citation" data-cites="Castellano_etal2014">(<a href="references.html#ref-Castellano_etal2014" role="doc-biblioref">Castellano, Rabe-Hesketh, and Skrondal 2014, 348</a>)</span>:</p>
<ul>
<li>the association between <span class="math inline">\(\bar{x}\)</span> and <span class="math inline">\(U\)</span> (<span class="math inline">\(\rho_{\bar{x}u}\)</span>)</li>
<li>the association between <span class="math inline">\(\bar{x}\)</span> and <span class="math inline">\(W\)</span> (<span class="math inline">\(\rho_{\bar{x}w}\)</span>)</li>
<li>the standard deviation of the random intercepts <span class="math inline">\(U\)</span> (<span class="math inline">\(\sigma_u\)</span>)</li>
<li>the standard deviation of <span class="math inline">\(W\)</span> (<span class="math inline">\(\sigma_w\)</span>)</li>
</ul>
<p>Here is the formula reported by <span class="citation" data-cites="Castellano_etal2014">Castellano, Rabe-Hesketh, and Skrondal (<a href="references.html#ref-Castellano_etal2014" role="doc-biblioref">2014</a>)</span>, p.&nbsp;348:</p>
<p><span class="math display">\[
\delta_\gamma = \frac{-\rho_{\bar{x}u}\rho_{\bar{x}w}\sigma_u}{\sigma_w(1-\rho^2_{\bar{x}w})}
\]</span></p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="06_token_level_predictors_files/figure-html/unnamed-chunk-22-1.png" class="img-fluid figure-img" width="192"></p>
</figure>
</div>
</div>
</div>
<p>The two-step estimator or the Hausmann-Taylor estimator produce an unbiased estimate for <span class="math inline">\(\gamma^{G}\)</span>, the direct causal effect of <span class="math inline">\(W\)</span> on <span class="math inline">\(Y\)</span>. An important aspect, however, is how the association between <code>mX</code> and <code>W</code> arises. Three possible underlying causal structures are shown in <a href="#fig-dag-bias-analysis-2" class="quarto-xref">Figure&nbsp;<span>7.13</span></a>. In panel (a) the association reflects a causal effect of <span class="math inline">\(W\)</span> on <span class="math inline">\(X\)</span>, which then surfaces in <span class="math inline">\(\bar{x}\)</span>. Panel (b) show a scenario where the association is due to a common cause U, which may be sitting at Level 1 or Level 2. Finally, panel (c) shows a direct causal effect of <span class="math inline">\(X\)</span> on <span class="math inline">\(W\)</span>, which gives rise to the association between <span class="math inline">\(\bar{x}\)</span> and <span class="math inline">\(W\)</span>. In settings (a) and (b), <span class="math inline">\(\bar{x}\)</span> is a collider on the path from <span class="math inline">\(U\)</span> to <span class="math inline">\(W\)</span>. Adjusting for <span class="math inline">\(\bar{x}\)</span> therefore opens a non-causal path that leads to bias in the direct causal effect of <span class="math inline">\(W\)</span> on <span class="math inline">\(Y\)</span>. In these scenarios, we would like to obtain an unbiased estimate. In panel (c), however, adjusting for <span class="math inline">\(\bar{x}\)</span> actually closes a backdoor path. Without this adjustment, our estimate of the direct causal effect of <span class="math inline">\(W\)</span> on <span class="math inline">\(Y\)</span> is confounded. This leads me to conclude that only scenarios (a) and (b) call for techniques such as 2S and HT.</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-dag-bias-analysis-2" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" width="422.4">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-dag-bias-analysis-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06_token_level_predictors_files/figure-html/fig-dag-bias-analysis-2-1.png" id="fig-dag-bias-analysis-2" class="img-fluid figure-img" width="422">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig quarto-uncaptioned margin-caption" id="fig-dag-bias-analysis-2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.13
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="simulation-1" class="level3" data-number="7.7.4">
<h3 data-number="7.7.4" class="anchored" data-anchor-id="simulation-1"><span class="header-section-number">7.7.4</span> Simulation</h3>
<p>Next, we carry out a bias analysis. We vary the parameters of the model to see what effect each one has on the amount of bias in the results.</p>
</section>
<section id="bias-decreases-with-increasing-cluster-size" class="level3" data-number="7.7.5">
<h3 data-number="7.7.5" class="anchored" data-anchor-id="bias-decreases-with-increasing-cluster-size"><span class="header-section-number">7.7.5</span> Bias decreases with increasing cluster size</h3>
<p>As cluster size increases, random intercept estimates approach their fixed counterparts. The bias in between-differences and other cluster-level predictors therefore decreases. As noted by <span class="citation" data-cites="Rabe-Hesketh_Skrondal2022">(<a href="references.html#ref-Rabe-Hesketh_Skrondal2022" role="doc-biblioref">Rabe-Hesketh and Skrondal 2021, 178</a>)</span></p>
<p>Let us run a bias analysis here:</p>
</section>
<section id="tools-for-consistent-estimation" class="level3" data-number="7.7.6">
<h3 data-number="7.7.6" class="anchored" data-anchor-id="tools-for-consistent-estimation"><span class="header-section-number">7.7.6</span> Tools for consistent estimation</h3>
<p>Under certain circumstances, there are strategies for obtaining consistent estimates for cluster-level coefficients. Thus, in cases where there is no contextual effect – i.e.&nbsp;where <span class="math inline">\(\beta^{\textrm{C}} = 0\)</span> or, equivalently, <span class="math inline">\(\beta^{\textrm{W}} = \beta^{\textrm{B}}\)</span> – we can obtain consistent estimates for cluster-level predictors (<span class="math inline">\(\gamma^{\textrm{G}}\)</span>), cluster-specific intercepts (<span class="math inline">\(\alpha_j^{\scriptsize{\textrm{RE}}}\)</span>) and the random-intercept variance (<span class="math inline">\(\sigma_{\alpha}\)</span>). More specifically, we can strip from these estimates the amount of bias that is due exclusively to Level-2 endogeneity of the Level-1 predictor.</p>
<p>The general strategy is the following. We first obtain a consistent estimate of <span class="math inline">\(\hat\beta^{\textrm{W}}\)</span> using one of the models discussed above. Recall that, apart from the naive multilevel model, all produce consistent estimates for <span class="math inline">\(\beta^{\textrm{W}}\)</span>. We then plug the estimate <span class="math inline">\(\hat\beta^{\textrm{W}}\)</span> into the following equation to get consistent estimates for <span class="math inline">\(\gamma^{\textrm{G}}\)</span>, :</p>
<p><span class="math display">\[
\begin{aligned}
y_{ij} - (\hat\beta^{\textrm{w}}x_{ij}) &amp;\sim \textrm{Normal}(\mu_{ij}, \sigma) \\
\mu_{ij} &amp;= \alpha_j^{\scriptsize{\textrm{RE}}} \\
\alpha_j^{\scriptsize{\textrm{RE}}} &amp;\sim \textrm{Normal}(\bar{\alpha}, \sigma_{\alpha}) \\
\bar{\alpha} &amp;= \gamma + \gamma^{\textrm{G}} G_j
\end{aligned}
\]</span> We can preserve the uncertainty in <span class="math inline">\(\hat\beta^{\textrm{W}}\)</span> with a Bayesian regression model.</p>
</section>
</section>
<section id="additional-complexities" class="level2 page-columns page-full" data-number="7.8">
<h2 data-number="7.8" class="anchored" data-anchor-id="additional-complexities"><span class="header-section-number">7.8</span> Additional complexities</h2>
<section id="correct-specification-of-the-between-pattern" class="level3 page-columns page-full" data-number="7.8.1">
<h3 data-number="7.8.1" class="anchored" data-anchor-id="correct-specification-of-the-between-pattern"><span class="header-section-number">7.8.1</span> Correct specification of the between-pattern</h3>
<p>In categorical regression models (e.g.&nbsp;logistic, multinomial, or count regression) the inclusion of cluster means may not reliably partition within- and between components in certain cases. For instance, if the association between cluster means and the outcome is non-linear but constrained by the model specification to linearity, the estimates for the within-cluster differences will be biased <span class="citation" data-cites="Bell_etal2019 Palta_Seplaki2003 Schnuck_Perales2017">(<a href="references.html#ref-Bell_etal2019" role="doc-biblioref">Bell, Fairbrother, and Jones 2019, 1066</a>; <a href="references.html#ref-Palta_Seplaki2003" role="doc-biblioref">Palta and Seplaki 2003, 188</a>; <a href="references.html#ref-Schnuck_Perales2017" role="doc-biblioref">Schnuck and Perales 2017, 109</a>)</span>. This is in contrast to ordinary linear regression. We should therefore be on the lookout for potential non-linearities during initial data analysis. As illustrated in <a href="#fig-tools-between-nonlinear" class="quarto-xref">Figure&nbsp;<span>7.14</span></a>, we can add a flexible summary of the trend to our bubble chart, e.g.&nbsp;in the form of a smoother or spline. In <a href="#fig-tools-between-nonlinear" class="quarto-xref">Figure&nbsp;<span>7.14</span></a>, where the grey trend line represents a fairly flexible spline with 3 knots, there is no indication of non-linearity.</p>
<div class="cell page-columns page-full">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-tools-between-nonlinear" class="quarto-float quarto-figure quarto-figure-center anchored" width="192">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tools-between-nonlinear-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06_token_level_predictors_files/figure-html/fig-tools-between-nonlinear-1.png" id="fig-tools-between-nonlinear" class="img-fluid figure-img" width="192">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-tools-between-nonlinear-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.14
</figcaption>
</figure>
</div>
</div></div></div>
<p>The between-cluster relationship may also show an interaction with other variables. It is usually best if interactions have a good linguistic footing, i.e.&nbsp;that there is reason to expect them on substantive grounds. For our illustrative case study, the data suggest an interaction between cluster means and frequency. <a href="#fig-ing-words-between-distribution-interaction" class="quarto-xref">Figure&nbsp;<span>7.15</span></a> divides words into three frequency bands using token counts of 5 and 20 as thresholds. We can see that the between-cluster trend is steeper among high-frequency words.</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-ing-words-between-distribution-interaction" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" width="422.4">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-ing-words-between-distribution-interaction-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06_token_level_predictors_files/figure-html/fig-ing-words-between-distribution-interaction-1.png" id="fig-ing-words-between-distribution-interaction" class="img-fluid figure-img" width="422">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig quarto-uncaptioned margin-caption" id="fig-ing-words-between-distribution-interaction-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.15
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="population-averaged-vs.-cluster-specific-estimates" class="level3" data-number="7.8.2">
<h3 data-number="7.8.2" class="anchored" data-anchor-id="population-averaged-vs.-cluster-specific-estimates"><span class="header-section-number">7.8.2</span> Population-averaged vs.&nbsp;cluster-specific estimates</h3>
<ul>
<li>The difficulty of comparing population-averaged differences (between-differences) and cluster-specific differences (within-differences). <span class="citation" data-cites="Neuhaus_Kalbfleisch1998">(<a href="references.html#ref-Neuhaus_Kalbfleisch1998" role="doc-biblioref">Neuhaus and Kalbfleisch 1998, 641</a>)</span> comment on this, but it seems that they miss the point that it does not make sense to interpret a between-subject difference on a subject-specific scale.</li>
</ul>
</section>
<section id="crossed-clustering-structures" class="level3" data-number="7.8.3">
<h3 data-number="7.8.3" class="anchored" data-anchor-id="crossed-clustering-structures"><span class="header-section-number">7.8.3</span> Crossed clustering structures</h3>
<ul>
<li>Use of deviation variables impossible?</li>
</ul>
</section>
<section id="random-slopes" class="level3" data-number="7.8.4">
<h3 data-number="7.8.4" class="anchored" data-anchor-id="random-slopes"><span class="header-section-number">7.8.4</span> Random slopes</h3>
<ul>
<li>What happens when we specify random slopes on <span class="math inline">\(\beta^*\)</span>?</li>
</ul>
</section>
<section id="contextual-effects-for-categorical-predictors" class="level3 page-columns page-full" data-number="7.8.5">
<h3 data-number="7.8.5" class="anchored" data-anchor-id="contextual-effects-for-categorical-predictors"><span class="header-section-number">7.8.5</span> Contextual effects for categorical predictors</h3>
<p>Token-level predictors can also be categorical, with 3 or more categories. This adds some complexity to the analysis since categorical predictors with <span class="math inline">\(k\)</span> levels are represented in a regression model by <span class="math inline">\(k - 1\)</span> contrasts. Binary and quantitative predictors can be represented in the model with one term. Cluster means then have to be included for each contrast, and we can distinguish within- and between-comparisons for each contrast. Graphically, we could therefore compare <span class="math inline">\(k - 1\)</span> trend-lines, similar to our visualization of binary predictors. The disadvantage of this multi-panel approach is that the individual contrasts themselves show a specific fragment of the patterns formed by the categorical predictor. Depending on which kind of contrast coding is used, these fragments may not be directly informative. We therefore introduce another visualization technique, which allows us to draw a more comprehensive comparison of between- and within-patterns of categorical predictors.</p>
<p>We start by fitting a Mundlak (or, equivalently, a between-within) model to isolate the within-comparisons for the token-level predictor. We then use these coefficients to compute for each cluster, the predicted outcome based on the composition of the cluster. We first compute the predicted outcome for each category and then weight these based on their share among the tokens for a particular cluster. This produces a weighted average reflecting the compositional effect.</p>
<p>We are then ready to produce a plot similar to <a href="#fig-between-within-categorical" class="quarto-xref">Figure&nbsp;<span>7.16</span></a>: The horizontal axis shows the cluster-specific weighted average reflecting the compositional effect. In the present case, this is expressed on the log-odds (or logit) scale. The vertical axis represents the observed share of ing for each cluster. The dashed trend line denotes the expected trend among the clusters based on the compositional effect. It is the value on the x-axis expressed as a proportion.</p>
<p>The lower panel in <a href="#fig-between-within-categorical" class="quarto-xref">Figure&nbsp;<span>7.16</span></a> shows the composition of the clusters. Thus, for each bubble in the top panel, the bottom panel shows four characters representing the share of each category: (c)oronal, o(t)her, (v)elar, (p)ause. Coronal contexts disfavor ing – words with high shares of pre-coronal tokens therefore appear towards the left end of the scale. A pause, on the other hand, favors ing. Words sitting at the right end of the scale therefore have a high share of pre-pausal tokens.</p>
<div class="cell page-columns page-full">
<div class="cell-output-display page-columns page-full">
<div id="fig-between-within-categorical" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full" width="264">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-between-within-categorical-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06_token_level_predictors_files/figure-html/fig-between-within-categorical-1.png" id="fig-between-within-categorical" class="img-fluid figure-img" width="264">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig quarto-uncaptioned margin-caption" id="fig-between-within-categorical-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.16
</figcaption>
</figure>
</div>
</div>
</div>
<p>If the data show only a compositional, and no contextual, effect, the dashed trend line will give a good approximation of the patterns formed by the bubbles representing the clusters. In <a href="#fig-between-within-categorical" class="quarto-xref">Figure&nbsp;<span>7.16</span></a>, we have added a solid trend line that gives a simple summary of the actual pattern formed by the bubbles in the graph. Similar to <a href="#fig-ing-words-between-distribution" class="quarto-xref">Figure&nbsp;<span>7.7</span></a> above, this allows us to obtain a visual comparison of within- and between-patterns in the data.</p>
</section>
</section>
<section id="within--and-between-effects-and-fallacies" class="level2" data-number="7.9">
<h2 data-number="7.9" class="anchored" data-anchor-id="within--and-between-effects-and-fallacies"><span class="header-section-number">7.9</span> Within- and between-effects and fallacies</h2>
<p>The distinction between within- and between-effects is related to some well-known fallacies in clustered data structures. Thus, the <em>ecological fallacy</em> describes a situation where we base our analysis on cluster means of a token-level predictor and then interpret the estimates as a within-cluster effect. The <em>atomistic fallacy</em>, on the other hand, refers to the situation where we ignore the clustering and interpret effects as between-effects.</p>
</section>
<section id="tools" class="level2 page-columns page-full" data-number="7.10">
<h2 data-number="7.10" class="anchored" data-anchor-id="tools"><span class="header-section-number">7.10</span> Tools</h2>
<section id="plotting-the-composition-of-clusters-using-a-dot-diagram" class="level3" data-number="7.10.1">
<h3 data-number="7.10.1" class="anchored" data-anchor-id="plotting-the-composition-of-clusters-using-a-dot-diagram"><span class="header-section-number">7.10.1</span> Plotting the composition of clusters using a dot diagram</h3>
<p>To graph the composition of clusters, we first use the package <code>dplyr</code> to determine the cluster means for the token-level predictor, which is here denoted by <code>X</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>ing_sample <span class="sc">%&gt;%</span> </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(word) <span class="sc">%&gt;%</span> </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mX =</span> <span class="fu">mean</span>(X))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This will return the following table:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre class="indent"><code># A tibble: 1,024 × 2
   word_2                    mX
   &lt;fct&gt;                  &lt;dbl&gt;
 1 going_verb            -0.845
 2 doing_verb            -0.752
 3 being_gerund          -0.752
 4 working_verb          -0.811
 5 trying_verb           -1    
 6 being_verb            -0.759
 7 interesting_adjective -0.333
 8 coming_verb           -0.732
 9 getting_verb          -0.744
10 going_gerund          -0.882
# ℹ 1,014 more rows</code></pre>
</div>
</div>
<p>We can pass this table on to a plotting call to produce a dot diagram. Before plotting, we filter out words that occur fewer than 5 times in the corpus.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>ing_sample <span class="sc">%&gt;%</span> </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(frequency <span class="sc">&gt;=</span><span class="dv">5</span>) <span class="sc">%&gt;%</span>     <span class="co"># exclude words that occur fewer than 5 times</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(word) <span class="sc">%&gt;%</span> </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mX =</span> <span class="fu">mean</span>(X)) <span class="sc">%&gt;%</span> </span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>mX)) <span class="sc">+</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_dotplot</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-fig.margin="true">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="06_token_level_predictors_files/figure-html/tools-between-within-dotdiagram-1.png" class="img-fluid figure-img" width="192"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="exploring-between-cluster-trends-using-a-bubble-chart" class="level3 page-columns page-full" data-number="7.10.2">
<h3 data-number="7.10.2" class="anchored" data-anchor-id="exploring-between-cluster-trends-using-a-bubble-chart"><span class="header-section-number">7.10.2</span> Exploring between-cluster trends using a bubble chart</h3>
<p>To draw a bubble chart, we first use <code>dplyr</code> to calculate the necessary cluster-level statistics, i.e.&nbsp;cluster means for the token-level predictor (<code>mX</code>), overall token count in the data set (<code>frequency</code>) and the overall share of ing for the cluster (<code>prop_ing</code>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>ing_sample <span class="sc">%&gt;%</span> </span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(word) <span class="sc">%&gt;%</span> </span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mX =</span> <span class="fu">mean</span>(X),</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">prop_ing =</span> <span class="fu">sum</span>(ing)<span class="sc">/</span><span class="fu">n</span>(),</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>            <span class="at">frequency =</span> <span class="fu">n</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This will return the following table:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre class="indent"><code># A tibble: 1,024 × 4
   word_2                    mX prop_ing frequency
   &lt;fct&gt;                  &lt;dbl&gt;    &lt;dbl&gt;     &lt;int&gt;
 1 going_verb            -0.845    0.345       386
 2 doing_verb            -0.752    0.438       226
 3 being_gerund          -0.752    0.578       161
 4 working_verb          -0.811    0.497       159
 5 trying_verb           -1        0.150       147
 6 being_verb            -0.759    0.481       133
 7 interesting_adjective -0.333    0.894       132
 8 coming_verb           -0.732    0.354       127
 9 getting_verb          -0.744    0.592       125
10 going_gerund          -0.882    0.445       119
# ℹ 1,014 more rows</code></pre>
</div>
</div>
<p>This table is then passed on to a plotting call to produce a bubble chart. In the <code>ggplot</code> call, we use the argument <code>size</code> to make the circles proportional to the token count. In <code>geom_point</code> the argument <code>alpha</code> serves to make the bubbles transparent. <code>geom_smooth</code> adds the trend line to the display, with a few additional settings to instruct R that we are looking at proportions (bounded by 0 and 1) and specify the weights for the data points (more frequent token have greater weight).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>ing_sample <span class="sc">%&gt;%</span> </span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(word_2) <span class="sc">%&gt;%</span> </span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">mX =</span> <span class="fu">mean</span>(foll_cont_bin_c),</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>            <span class="at">prop_ing =</span> <span class="fu">sum</span>(ing)<span class="sc">/</span><span class="fu">n</span>(),</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>            <span class="at">frequency =</span> <span class="fu">n</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x=</span>mX, <span class="at">y=</span>prop_ing, <span class="at">size=</span><span class="fu">sqrt</span>(frequency<span class="sc">/</span>pi))) <span class="sc">+</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">shape=</span><span class="dv">1</span>, <span class="at">alpha=</span>.<span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"glm"</span>,</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>              <span class="at">method.args =</span> <span class="fu">list</span>(<span class="at">family =</span> <span class="st">"binomial"</span>),</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>              <span class="fu">aes</span>(<span class="at">weight =</span> frequency), <span class="at">se=</span>F) <span class="sc">+</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_size_identity</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell page-columns page-full">

<div class="no-row-height column-margin column-container"><div class="cell-output-display">
<div id="fig-tools-between-within-bubblechart" class="quarto-float quarto-figure quarto-figure-center anchored" width="192">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tools-between-within-bubblechart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="06_token_level_predictors_files/figure-html/fig-tools-between-within-bubblechart-1.png" id="fig-tools-between-within-bubblechart" class="img-fluid figure-img" width="192">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig quarto-uncaptioned" id="fig-tools-between-within-bubblechart-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7.17
</figcaption>
</figure>
</div>
</div></div></div>
</section>
<section id="recoding-token-level-predictors-in-r" class="level3" data-number="7.10.3">
<h3 data-number="7.10.3" class="anchored" data-anchor-id="recoding-token-level-predictors-in-r"><span class="header-section-number">7.10.3</span> Recoding token-level predictors in R</h3>
<p>To specify a between-within model and a Mundlak model, we need to add two new variables to our data frame: (i) cluster means <code>mX</code> and (ii) the cluster-mean centered version of the token-level predictor <code>dX</code>. We can do this using <code>dplyr</code>:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>ing_sample <span class="sc">%&gt;%</span> </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(word) <span class="sc">%&gt;%</span> </span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">mX =</span> <span class="fu">mean</span>()) <span class="sc">%&gt;%</span> </span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">dX =</span> X <span class="sc">-</span> mX)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This will return the following table:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre class="indent"><code># A tibble: 6,314 × 4
   word_2                 X     mX     dX
   &lt;fct&gt;              &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
 1 morning_noun          -1 -0.489 -0.511
 2 engineering_gerund    -1 -0.125 -0.875
 3 falling_verb          -1 -1      0    
 4 walking_verb          -1 -0.895 -0.105
 5 working_gerund        -1 -0.634 -0.366
 6 trying_verb           -1 -1      0    
 7 trying_verb           -1 -1      0    
 8 trying_verb           -1 -1      0    
 9 trying_verb           -1 -1      0    
10 going_verb            -1 -0.845 -0.155
# ℹ 6,304 more rows</code></pre>
</div>
</div>
</section>
<section id="model-syntax" class="level3" data-number="7.10.4">
<h3 data-number="7.10.4" class="anchored" data-anchor-id="model-syntax"><span class="header-section-number">7.10.4</span> Model syntax</h3>
<p>Specifying the models is then straightforward with these new variables:</p>
<p>Between-within model:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glmer</span>(ing <span class="sc">~</span> dX <span class="sc">+</span> mX <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>word), <span class="at">data=</span>ing_sample, <span class="at">family=</span>binomial)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Mundlak model:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glmer</span>(ing <span class="sc">~</span> X <span class="sc">+</span> mX <span class="sc">+</span> (<span class="dv">1</span><span class="sc">|</span>word), <span class="at">data=</span>ing_sample, <span class="at">family=</span>binomial)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="literature-on-between--and-within-comparisons" class="level2" data-number="7.11">
<h2 data-number="7.11" class="anchored" data-anchor-id="literature-on-between--and-within-comparisons"><span class="header-section-number">7.11</span> Literature on between- and within comparisons</h2>
<p>Raudenbush &amp; Willms 1995 How does this connect to Gelman &amp; Hill (2007: 310-314) How does this connect to the BK plot (Wainer 2005, chapter 10)</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-Allison2009" class="csl-entry" role="listitem">
Allison, Paul D. 2009. <em>Fixed Effects Regression Models</em>. Thousand Oaks, CA: Sage.
</div>
<div id="ref-Begg_Parides2003" class="csl-entry" role="listitem">
Begg, Melissa D., and Michael K. Parides. 2003. <span>“Separation of Individual-Level and Cluster-Level Covariate Effects in Regression Analysis of Correlated Data.”</span> <em>Statistics in Medicine</em>, no. 22: 2591–2602. <a href="https://doi.org/10.1002/sim.1524">https://doi.org/10.1002/sim.1524</a>.
</div>
<div id="ref-Bell_etal2019" class="csl-entry" role="listitem">
Bell, Andrew, Malcolm Fairbrother, and Kelvyn Jones. 2019. <span>“Fixed and Random Effects Models: Making an Informed Choice.”</span> <em>Quality &amp; Quantity</em> 53: 1051–74. <a href="https://doi.org/10.1007/s11135-018-0802-x">https://doi.org/10.1007/s11135-018-0802-x</a>.
</div>
<div id="ref-Bingenheimer_Raudenbush2004" class="csl-entry" role="listitem">
Bingenheimer, Jeffrey B., and Stephen W. Raudenbush. 2004. <span>“Statistical and Substantive Inferences in Public Health: <span>Issues</span> in the Application of Multilevel Models.”</span> <em>Annual Review of Public Health</em>, no. 25: 53–77. <a href="https://doi.org/10.1146/annurev.publhealth.25.050503.153925">https://doi.org/10.1146/annurev.publhealth.25.050503.153925</a>.
</div>
<div id="ref-Cameron_Trivedi2005" class="csl-entry" role="listitem">
Cameron, A. Colin, and Pravin K. Trivedi. 2005. <em>Microeconometrics: <span>M</span>ethods and Applications</em>. Cambridge: Cambridge University Press.
</div>
<div id="ref-Castellano_etal2014" class="csl-entry" role="listitem">
Castellano, Katherine E., Sophia Rabe-Hesketh, and Anders Skrondal. 2014. <span>“Composition, Context, and Endogeneity in School and Teacher Comparisons.”</span> <em>Journal of Educational and Behavioral Statistics</em> 39 (5): 333–67. <a href="https://doi.org/10.3102/1076998614547576">https://doi.org/10.3102/1076998614547576</a>.
</div>
<div id="ref-Diez-Roux2002" class="csl-entry" role="listitem">
Diez Roux, Ana M. 2002. <span>“A Glossary for Multilevel Analysis.”</span> <em>Journal of Epidemiology and Community Health</em> 56: 558–94. <a href="https://doi.org/10.1136/jech.56.8.588">https://doi.org/10.1136/jech.56.8.588</a>.
</div>
<div id="ref-Duncan_etal1998" class="csl-entry" role="listitem">
Duncan, Craig, Kelvyn Jones, and Graham Moon. 1998. <span>“Context, Composition and Heterogeneity: <span>Using</span> Multilevel Models in Health Research.”</span> <em>Social Science &amp; Medicine</em> 1 (46): 97–117. <a href="https://doi.org/10.1016/s0277-9536(97)00148-2">https://doi.org/10.1016/s0277-9536(97)00148-2</a>.
</div>
<div id="ref-Ebbes_etal2004" class="csl-entry" role="listitem">
Ebbes, Peter, Ulf Böckenholt, and Michel Wedel. 2004. <span>“Regressor and Random-Effects Dependencies in Multilevel Models.”</span> <em>Statistica Neerlandica</em> 58 (2): 161–78. <a href="https://doi.org/10.1046/j.0039-0402.2003.00254.x">https://doi.org/10.1046/j.0039-0402.2003.00254.x</a>.
</div>
<div id="ref-Hausman1978" class="csl-entry" role="listitem">
Hausman, Jerry A. 1978. <span>“Specification Tests in Econometrics.”</span> <em>Econometrica</em> 46: 1251–71. <a href="https://doi.org/10.2307/1913827">https://doi.org/10.2307/1913827</a>.
</div>
<div id="ref-Mundlak1978" class="csl-entry" role="listitem">
Mundlak, Yair. 1978. <span>“On the Pooling of Time Series and Cross Section Data.”</span> <em>Econometrica</em> 46 (1): 69–85. <a href="https://doi.org/1913646">https://doi.org/1913646</a>.
</div>
<div id="ref-Neuhaus_Kalbfleisch1998" class="csl-entry" role="listitem">
Neuhaus, J. M., and J. D. Kalbfleisch. 1998. <span>“Between- and Within-Cluster Covariate Effects in the Analysis of Clustered Data.”</span> <em>Biometrics</em>, no. 54: 638–45.
</div>
<div id="ref-Palta_Seplaki2003" class="csl-entry" role="listitem">
Palta, Mari, and Chris Seplaki. 2003. <span>“Causes, Problems and Benefits of Different Between and Within Effects in the Analysis of Clustered Data.”</span> <em>Health Services and Outcomes Research Methodology</em>, no. 3: 177–93. <a href="https://doi.org/10.1023/A:1025893627073">https://doi.org/10.1023/A:1025893627073</a>.
</div>
<div id="ref-Rabe-Hesketh_Skrondal2022" class="csl-entry" role="listitem">
Rabe-Hesketh, Sophia, and Anders Skrondal. 2021. <em>Multilevel and Longitudinal Modeling Using <span>Stata</span></em>. College Station, TX: Stata Press.
</div>
<div id="ref-Raudenbush_Bryk2002" class="csl-entry" role="listitem">
Raudenbush, Stephen W., and Anthony S. Bryk. 2002. <em>Hierarchical Linear Models: <span>Applications</span> and Data Analysis Methods</em>. Thousand Oaks, CA: Sage.
</div>
<div id="ref-Schnuck_Perales2017" class="csl-entry" role="listitem">
Schnuck, Reinhard, and Francisco Perales. 2017. <span>“Within- and Between-Cluster Effects in Generalized Linear Mixed Models: <span>A</span> Discussion of Approaches and the Xthybrid Command.”</span> <em>The Stata Journal</em> 17 (1): 89–115. <a href="https://doi.org/10.1177/1536867X1701700106">https://doi.org/10.1177/1536867X1701700106</a>.
</div>
<div id="ref-Sjölander_etal2013" class="csl-entry" role="listitem">
Sjölander, Arvid, Paul Lichtenstein, Henrik Larsson, and Yudi Pawitan. 2013. <span>“Between–Within Models for Survival Analysis.”</span> <em>Statistics in Medicine</em> 18 (32): 3067–76. <a href="https://doi.org/10.1002/sim.5767">https://doi.org/10.1002/sim.5767</a>.
</div>
<div id="ref-Wooldridge2010" class="csl-entry" role="listitem">
Wooldridge, Jeffrey M. 2010. <em>Econometric Analysis of Cross Section and Panel Data</em>. Cambridge, MA: MIT Press.
</div>
</div>
</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./05_model_specification.html" class="pagination-link" aria-label="Model specification">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Model specification</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./07_foregrounding_variation.html" class="pagination-link" aria-label="Foregrounding variation">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Foregrounding variation</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>